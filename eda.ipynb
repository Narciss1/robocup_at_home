{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08faf596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb78d039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load env variables from .env file\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122216f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_id = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=0.05,  # <-- Super slow! We can only make a request once every 10 seconds!!\n",
    "    check_every_n_seconds=0.1,  # Wake up every 100 ms to check whether allowed to make a request,\n",
    "    max_bucket_size=10,  # Controls the maximum burst size.\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "# graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28238567",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph must have an entrypoint: add at least one edge from START to another node",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/graph/state.py:539\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[0;34m(self, checkpointer, store, interrupt_before, interrupt_after, debug, name)\u001b[0m\n\u001b[1;32m    536\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[1;32m    548\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m     ]\n\u001b[1;32m    557\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/graph/graph.py:377\u001b[0m, in \u001b[0;36mGraph.validate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound edge starting at unknown node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# assemble targets\u001b[39;00m\n\u001b[1;32m    382\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m {end \u001b[38;5;28;01mfor\u001b[39;00m _, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_edges}\n",
      "\u001b[0;31mValueError\u001b[0m: Graph must have an entrypoint: add at least one edge from START to another node"
     ]
    }
   ],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f688b051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30167934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm **DeepSeek Chat**, an AI assistant created by **DeepSeek**, and hereâ€™s what I can do for you:  \n",
      "\n",
      "### ðŸ” **Knowledge & Assistance**  \n",
      "- Answer questions on diverse topics (science, history, tech, entertainment, etc.).  \n",
      "- Provide explanations, summaries, and detailed analyses.  \n",
      "- Offer step-by-step problem-solving for math, coding, and logic puzzles.  \n",
      "\n",
      "### ðŸ“„ **Document Processing**  \n",
      "- Read and analyze uploaded documents (**PDFs, Word, Excel, PowerPoint, TXT**).  \n",
      "- Extract key information, summarize content, or answer questions about the document.  \n",
      "\n",
      "### ðŸ“ **Writing & Editing**  \n",
      "- Help with essays, reports, emails, and creative writing (stories, poems, scripts).  \n",
      "- Rewrite, proofread, or refine your text for clarity and style.  \n",
      "\n",
      "### ðŸ’» **Coding & Tech Support**  \n",
      "- Write, debug, and optimize code in Python, Java, C++, JavaScript, and more.  \n",
      "- Explain programming concepts, algorithms, and best practices.  \n",
      "\n",
      "### ðŸŒ **Translation & Language Skills**  \n",
      "- Translate between multiple languages (accurate but not perfect).  \n",
      "- Teach vocabulary, grammar, and conversational phrases.  \n",
      "\n",
      "### ðŸ”¢ **Math & Data Analysis**  \n",
      "- Solve equations, explain mathematical theories, and assist with statistics.  \n",
      "- Generate charts, graphs (via explanations), and help with data formatting.  \n",
      "\n",
      "### ðŸŽ­ **Creative & Fun Stuff**  \n",
      "- Generate jokes, stories, movie plots, and roleplay scenarios.  \n",
      "- Assist with brainstorming ideas for projects, branding, or content.  \n",
      "\n",
      "### âš¡ **Limitations** (for transparency)  \n",
      "- My knowledge is **updated until July 2024** (no real-time info).  \n",
      "- I cannot access images/audioâ€”only text from documents.  \n",
      "- I wonâ€™t perform illegal or harmful tasks.  \n",
      "\n",
      "Need something specific? Just askâ€”Iâ€™m happy to help! ðŸš€\n",
      "Assistant: Iâ€™m **DeepSeek Chat**, an AI assistant created by **DeepSeek**. My goal is to help you with information, answer your questions, and assist with tasks like research, writing, coding, and more! ðŸ˜Š  \n",
      "\n",
      "Iâ€™m powered by **DeepSeek-V3**, a large language model with a knowledge cutoff in **July 2024**, and I can even search the web (if you enable it) for the latest updates.  \n",
      "\n",
      "Feel free to ask me anythingâ€”Iâ€™m here to help! ðŸš€\n",
      "User: What do you know about LangGraph?\n",
      "Assistant: **LangGraph** is a library developed by **LangChain** designed for building stateful, multi-actor applications with **Large Language Models (LLMs)**. It extends LangChain's core functionality by enabling the creation of cyclic, stateful workflows (graphs) where multiple agents or nodes can interact dynamically.\n",
      "\n",
      "### **Key Features of LangGraph:**\n",
      "1. **Stateful Workflows**  \n",
      "   - Unlike traditional linear chains, LangGraph allows cycles and state persistence, making it suitable for complex, iterative processes (e.g., multi-agent debates, recursive reasoning).\n",
      "\n",
      "2. **Multi-Agent Collaboration**  \n",
      "   - Supports multiple AI agents (or human actors) working together, passing messages and updating shared state.\n",
      "\n",
      "3. **Flexible Control Flow**  \n",
      "   - Combines **directed graphs** (for structured flows) with **cycles** (for loops, feedback, or self-correction).  \n",
      "   - Example: An agent can refine its answer iteratively based on feedback.\n",
      "\n",
      "4. **Integration with LangChain**  \n",
      "   - Works seamlessly with LangChain's existing tools (models, retrievers, prompts, etc.) while adding advanced orchestration.\n",
      "\n",
      "5. **Human-in-the-Loop**  \n",
      "   - Supports human input at specific points in the workflow (e.g., approval steps).\n",
      "\n",
      "---\n",
      "\n",
      "### **Use Cases**\n",
      "- **Agent Simulations**: Simulate interactions between multiple AI agents.  \n",
      "- **Recursive Problem-Solving**: Tasks requiring refinement (e.g., code generation with error correction).  \n",
      "- **Dynamic Chatbots**: Multi-turn conversations with memory.  \n",
      "- **Decision-Making Pipelines**: Workflows where intermediate steps influence later actions.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example Workflow**\n",
      "A simple LangGraph workflow might involve:\n",
      "1. An **LLM node** generating an answer.  \n",
      "2. A **validator node** checking the answer.  \n",
      "3. A **feedback loop** to refine the answer if validation fails.  \n",
      "\n",
      "```python\n",
      "from langgraph.graph import Graph\n",
      "\n",
      "workflow = Graph()\n",
      "\n",
      "# Define nodes (e.g., LLM calls, tools)\n",
      "workflow.add_node(\"generate\", generate_response)\n",
      "workflow.add_node(\"validate\", validate_response)\n",
      "\n",
      "# Define edges (control flow)\n",
      "workflow.add_edge(\"generate\", \"validate\")\n",
      "workflow.add_conditional_edges(\"validate\", decide_to_finish_or_retry)\n",
      "\n",
      "# Compile and run\n",
      "app = workflow.compile()\n",
      "app.invoke({\"question\": \"...\"})\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Comparison to LangChain**\n",
      "- **LangChain**: Focuses on linear chains (prompt â†’ LLM â†’ output).  \n",
      "- **LangGraph**: Extends this with cycles, state, and multi-agent coordination.  \n",
      "\n",
      "---\n",
      "\n",
      "### **Getting Started**\n",
      "- **Installation**:  \n",
      "  ```bash\n",
      "  pip install langgraph\n",
      "  ```\n",
      "- **Documentation**:  \n",
      "  Check the [LangGraph GitHub](https://github.com/langchain-ai/langgraph) or [LangChain docs](https://python.langchain.com/docs/langgraph).\n",
      "\n",
      "Would you like a deeper dive into a specific feature or use case?\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9752a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from enum import Enum\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class LocationEnum(str, Enum):\n",
    "    kitchen = \"kitchen\"\n",
    "    living_room = \"living_room\"\n",
    "    bedroom = \"bedroom\"\n",
    "\n",
    "@tool\n",
    "def go_to_coordinates(x: float, y: float):\n",
    "    \"\"\"\n",
    "    Move the robot to a specific set of coordinates.\n",
    "    Args:\n",
    "        x (float): The x coordinate.\n",
    "        y (float): The y coordinate.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If x or y is not a number.\n",
    "    Example:\n",
    "        >>> go_to_coordinates(10.5, 20.3)\n",
    "        {'status': 'success', 'message': 'Moved to coordinates (10.5, 20.3)'}\n",
    "    Example:\n",
    "        >>> go_to_coordinates(\"10.5\", 20.3)\n",
    "        ValueError: x and y must be numbers.\n",
    "    Example:\n",
    "        >>> go_to_coordinates(10.5, 20.3)\n",
    "        {'status': 'failure', 'message': 'Failed to move to coordinates (10.5, 20.3)'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving to coordinates ({x}, {y})\")\n",
    "    # Here you would add the code to move the robot to the specified coordinates\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved to coordinates ({x}, {y})\"}\n",
    "\n",
    "@tool\n",
    "def go_to_location(location_name: LocationEnum):\n",
    "    \"\"\"\n",
    "    Move the robot to a specific location.\n",
    "    Args:\n",
    "        location_name (LocationEnum): The name of the location.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If location_name is not a valid location.\n",
    "    Example:\n",
    "        >>> go_to_location(\"kitchen\")\n",
    "        {'status': 'success', 'message': 'Moved to location: kitchen'}\n",
    "    Example:\n",
    "        >>> go_to_location(\"garage\")\n",
    "        ValueError: location_name must be one of ['kitchen', 'living_room', 'bedroom'].\n",
    "    Example:\n",
    "        >>> go_to_location(\"living_room\")\n",
    "        {'status': 'failure', 'message': 'Failed to move to location: living_room'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving to location: {location_name}\")\n",
    "    # Here you would add the code to move the robot to the specified location\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved to location: {location_name}\"}\n",
    "\n",
    "@tool\n",
    "def rotate(angle: float):\n",
    "    \"\"\"\n",
    "    Rotate the robot to a specific angle.\n",
    "    Args:\n",
    "        angle (float): The angle to rotate to.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If angle is not a number.\n",
    "    Example:\n",
    "        >>> rotate(90)\n",
    "        {'status': 'success', 'message': 'Rotated to angle: 90'}\n",
    "    Example:\n",
    "        >>> rotate(\"90\")\n",
    "        ValueError: angle must be a number.\n",
    "    Example:\n",
    "        >>> rotate(90)\n",
    "        {'status': 'failure', 'message': 'Failed to rotate to angle: 90'}\n",
    "    \"\"\"\n",
    "    print(f\"Rotating to angle: {angle}\")\n",
    "    # Here you would add the code to rotate the robot to the specified angle\n",
    "    return {\"status\": \"success\", \"message\": f\"Rotated to angle: {angle}\"}\n",
    "\n",
    "@tool\n",
    "def get_pose():\n",
    "    \"\"\"\n",
    "    Get the current pose of the robot.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> get_pose()\n",
    "        {'status': 'success', 'message': 'Current pose: (x, y, theta)'}\n",
    "    Example:\n",
    "        >>> get_pose()\n",
    "        {'status': 'failure', 'message': 'Failed to get pose'}\n",
    "    \"\"\"\n",
    "    print(\"Getting current pose\")\n",
    "    # Here you would add the code to get the current pose of the robot\n",
    "    return {\"status\": \"success\", \"message\": \"Current pose: (x, y, theta)\"}\n",
    "\n",
    "@tool\n",
    "def follow_person():\n",
    "    \"\"\"\n",
    "    Follow a person.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> follow_person()\n",
    "        {'status': 'success', 'message': 'Following person'}\n",
    "    Example:\n",
    "        >>> follow_person()\n",
    "        {'status': 'failure', 'message': 'Failed to follow person'}\n",
    "    \"\"\"\n",
    "    print(\"Following person\")\n",
    "    # Here you would add the code to follow a person\n",
    "    return {\"status\": \"success\", \"message\": \"Following person\"}\n",
    "\n",
    "nav_tools = [\n",
    "    go_to_coordinates,\n",
    "    go_to_location,\n",
    "    rotate,\n",
    "    get_pose,\n",
    "    follow_person\n",
    "]\n",
    "nav_llm_with_tools = llm.bind_tools(nav_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3221a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent system prompts\n",
    "sub_str = \"\"\"\n",
    "                'plan': \\[\n",
    "                            \\{'tool': 'tool_name': parameters: \\[param1,...,paramN\\], 'parallel': True/False \\},\n",
    "                            ...\n",
    "                        \\]\n",
    "        \"\"\"\n",
    "agent_sys_msg = lambda module: f\"\"\"You are the {module} head of a Robot, you have access to a set of tools that represent the robot's capabilities and\n",
    "                        you are tasked with translating a user's natural language command to one of the available tools with the appropriate parameters.\n",
    "                        Note that you can chain several tools together to fulfill a user command, you can also specify whether to run tools in parallel or sequentially.\n",
    "                        You have a set of tools at your disposal, each with its own set of parameters, you can call the tools, but you must\n",
    "                        also provide a concise reasoning for your choice in the tool_messages section for each one of the tool_calls.\n",
    "                        \"\"\"\n",
    "\n",
    "planning_sys_msg = \"\"\"You are the planning head of a robot that has several capabilities, you have access to several specialized agents,\n",
    "                        each with its own set of capabilities.\n",
    "                        You are tasked with finding the best plan to execute on the user's command based on the agents you have at disposal\n",
    "                        and their capabilities.\n",
    "                        You can also specify wheter to run commands sequentially or in parallel.\n",
    "                        Your output should be very precise and concise.\n",
    "                        The agent names are the following: [\"conversation\", \"manipulation\", \"navigation\", \"vision\"]\n",
    "                        Output format:\n",
    "                        'reasoning': Explain the overarching goal and how you plan to achieve it (be very concise)\n",
    "                        'plan': \\[\n",
    "                                    \\{'agent': 'agent_name', 'command': 'the command to be run by the agent', 'parallel': True/False \\},\n",
    "                                    ...\n",
    "                                \\]\n",
    "                        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ce3f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "def navigation_agent(state: MessagesState):\n",
    "    return {\"messages\": [nav_llm_with_tools.invoke([agent_sys_msg(module=\"navigation\")] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4bffb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation tools\n",
    "\n",
    "@tool\n",
    "def move_arm(x: float, y: float):\n",
    "    \"\"\"\n",
    "    Move the robot's arm to a specific position.\n",
    "    Args:\n",
    "        x (float): The x coordinate.\n",
    "        y (float): The y coordinate.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> move_arm(10.5, 20.3)\n",
    "        {'status': 'success', 'message': 'Moved arm to coordinates (10.5, 20.3)'}\n",
    "    Example:\n",
    "        >>> move_arm(\"10.5\", 20.3)\n",
    "        ValueError: x and y must be numbers.\n",
    "    Example:\n",
    "        >>> move_arm(10.5, 20.3)\n",
    "        {'status': 'failure', 'message': 'Failed to move arm to coordinates (10.5, 20.3)'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving arm to coordinates ({x}, {y})\")\n",
    "    # Here you would add the code to move the robot's arm to the specified coordinates\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved arm to coordinates ({x}, {y})\"}\n",
    "\n",
    "@tool\n",
    "def move_joints(joint_angles: list):\n",
    "    \"\"\"\n",
    "    Move the robot's joints to specific angles.\n",
    "    Args:\n",
    "        joint_angles (list): A list of joint angles.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> move_joints([30, 45, 60])\n",
    "        {'status': 'success', 'message': 'Moved joints to angles [30, 45, 60]'}\n",
    "    Example:\n",
    "        >>> move_joints(\"30, 45, 60\")\n",
    "        ValueError: joint_angles must be a list of numbers.\n",
    "    Example:\n",
    "        >>> move_joints([30, 45, 60])\n",
    "        {'status': 'failure', 'message': 'Failed to move joints to angles [30, 45, 60]'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving joints to angles {joint_angles}\")\n",
    "    # Here you would add the code to move the robot's joints to the specified angles\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved joints to angles {joint_angles}\"}\n",
    "\n",
    "@tool\n",
    "def pick_up_object(object_name: str):\n",
    "    \"\"\"\n",
    "    Pick up an object.\n",
    "    Args:\n",
    "        object_name (str): The name of the object to pick up.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> pick_up_object(\"box\")\n",
    "        {'status': 'success', 'message': 'Picked up object: box'}\n",
    "    Example:\n",
    "        >>> pick_up_object(123)\n",
    "        ValueError: object_name must be a string.\n",
    "    Example:\n",
    "        >>> pick_up_object(\"box\")\n",
    "        {'status': 'failure', 'message': 'Failed to pick up object: box'}\n",
    "    \"\"\"\n",
    "    print(f\"Picking up object: {object_name}\")\n",
    "    # Here you would add the code to pick up the specified object\n",
    "    return {\"status\": \"success\", \"message\": f\"Picked up object: {object_name}\"}\n",
    "\n",
    "@tool\n",
    "def press_button(button_name: str):\n",
    "    \"\"\"\n",
    "    Press a button.\n",
    "    Args:\n",
    "        button_name (str): The name of the button to press.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> press_button(\"start\")\n",
    "        {'status': 'success', 'message': 'Pressed button: start'}\n",
    "    Example:\n",
    "        >>> press_button(123)\n",
    "        ValueError: button_name must be a string.\n",
    "    Example:\n",
    "        >>> press_button(\"start\")\n",
    "        {'status': 'failure', 'message': 'Failed to press button: start'}\n",
    "    \"\"\"\n",
    "    print(f\"Pressing button: {button_name}\")\n",
    "    # Here you would add the code to press the specified button\n",
    "    return {\"status\": \"success\", \"message\": f\"Pressed button: {button_name}\"}\n",
    "\n",
    "manip_llm = ChatOpenAI(\n",
    "        \n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "manip_tools = [\n",
    "    move_arm,\n",
    "    move_joints,\n",
    "    pick_up_object\n",
    "]\n",
    "nav_tools = [\n",
    "    go_to_coordinates,\n",
    "    go_to_location,\n",
    "    rotate,\n",
    "    get_pose,\n",
    "    follow_person\n",
    "]\n",
    "manip_llm_with_tools = manip_llm.bind_tools(manip_tools)\n",
    "def manipulation_agent(state: MessagesState):\n",
    "    return {\"messages\": [manip_llm_with_tools.invoke([agent_sys_msg(module=\"navigation\")] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e735f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vision_llm = ChatOpenAI(\n",
    "        \n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "vision_tools = [\n",
    "    take_picture,\n",
    "    detect_objects,\n",
    "    recognize_text,\n",
    "    semantic_segmentation\n",
    "]\n",
    "manip_tools = [\n",
    "    move_arm,\n",
    "    move_joints,\n",
    "    pick_up_object\n",
    "]\n",
    "nav_tools = [\n",
    "    go_to_coordinates,\n",
    "    go_to_location,\n",
    "    rotate,\n",
    "    get_pose,\n",
    "    follow_person\n",
    "]\n",
    "\n",
    "vision_llm_with_tools = vision_llm.bind_tools(vision_tools)\n",
    "def vision_agent(state: MessagesState):\n",
    "    return {\"messages\": [vision_llm_with_tools.invoke([agent_sys_msg(module=\"vision\")] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41214629",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'take_picture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 59\u001b[0m\n\u001b[1;32m     47\u001b[0m conv_llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m     48\u001b[0m         \n\u001b[1;32m     49\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m     50\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     51\u001b[0m         max_completion_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     54\u001b[0m conv_tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m     clarify,\n\u001b[1;32m     56\u001b[0m     speak\n\u001b[1;32m     57\u001b[0m ]\n\u001b[1;32m     58\u001b[0m vision_tools \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mtake_picture\u001b[49m,\n\u001b[1;32m     60\u001b[0m     detect_objects,\n\u001b[1;32m     61\u001b[0m     recognize_text,\n\u001b[1;32m     62\u001b[0m     semantic_segmentation\n\u001b[1;32m     63\u001b[0m ]\n\u001b[1;32m     64\u001b[0m manip_tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     65\u001b[0m     move_arm,\n\u001b[1;32m     66\u001b[0m     move_joints,\n\u001b[1;32m     67\u001b[0m     pick_up_object\n\u001b[1;32m     68\u001b[0m ]\n\u001b[1;32m     69\u001b[0m nav_tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     70\u001b[0m     go_to_coordinates,\n\u001b[1;32m     71\u001b[0m     go_to_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     follow_person\n\u001b[1;32m     75\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'take_picture' is not defined"
     ]
    }
   ],
   "source": [
    "# Conversational tools\n",
    "@tool\n",
    "def clarify(context: str, question: str):\n",
    "    \"\"\"\n",
    "    Clarify a question based on the context.\n",
    "    Args:\n",
    "        context (str): The context to clarify the question.\n",
    "        question (str): The question to clarify.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", \"Where is the robot?\")\n",
    "        {'status': 'success', 'message': 'The robot is in the kitchen.'}\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", 123)\n",
    "        ValueError: question must be a string.\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", \"Where is the robot?\")\n",
    "        {'status': 'failure', 'message': 'Failed to clarify the question.'}\n",
    "    \"\"\"\n",
    "    print(f\"Clarifying question: {question} based on context: {context}\")\n",
    "    # Here you would add the code to clarify the question based on the context\n",
    "    return {\"status\": \"success\", \"message\": f\"The robot is in the kitchen.\"}\n",
    "\n",
    "@tool\n",
    "def speak(text: str):\n",
    "    \"\"\"\n",
    "    Speak a given text.\n",
    "    Args:\n",
    "        text (str): The text to speak.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> speak(\"Hello, world!\")\n",
    "        {'status': 'success', 'message': 'Spoken text: Hello, world!'}\n",
    "    Example:\n",
    "        >>> speak(123)\n",
    "        ValueError: text must be a string.\n",
    "    Example:\n",
    "        >>> speak(\"Hello, world!\")\n",
    "        {'status': 'failure', 'message': 'Failed to speak text: Hello, world!'}\n",
    "    \"\"\"\n",
    "    print(f\"Speaking text: {text}\")\n",
    "    # Here you would add the code to speak the given text\n",
    "    return {\"status\": \"success\", \"message\": f\"Spoken text: {text}\"}\n",
    "\n",
    "conv_llm = ChatOpenAI(\n",
    "        \n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "conv_tools = [\n",
    "    clarify,\n",
    "    speak\n",
    "]\n",
    "vision_tools = [\n",
    "    take_picture,\n",
    "    detect_objects,\n",
    "    recognize_text,\n",
    "    semantic_segmentation\n",
    "]\n",
    "manip_tools = [\n",
    "    move_arm,\n",
    "    move_joints,\n",
    "    pick_up_object\n",
    "]\n",
    "nav_tools = [\n",
    "    go_to_coordinates,\n",
    "    go_to_location,\n",
    "    rotate,\n",
    "    get_pose,\n",
    "    follow_person\n",
    "]\n",
    "conv_llm_with_tools = conv_llm.bind_tools(conv_tools)\n",
    "def conv_agent(state: MessagesState):\n",
    "    return {\"messages\": [conv_llm_with_tools.invoke([agent_sys_msg(module=\"conversation\")] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e977c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_llm = ChatOpenAI(\n",
    "        \n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=1000\n",
    "    )\n",
    "\n",
    "def planning_agent(state: MessagesState):\n",
    "    return {\"messages\": [planning_llm.invoke([planning_sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3220d22c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Add the nodes to the graph\u001b[39;00m\n\u001b[1;32m     12\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplanning\u001b[39m\u001b[38;5;124m\"\u001b[39m, planning_agent)\n\u001b[0;32m---> 13\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mconv_agent\u001b[49m)\n\u001b[1;32m     14\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanipulation\u001b[39m\u001b[38;5;124m\"\u001b[39m, manipulation_agent)\n\u001b[1;32m     15\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnavigation\u001b[39m\u001b[38;5;124m\"\u001b[39m, navigation_agent)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_agent' is not defined"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes to the graph\n",
    "builder.add_node(\"planning\", planning_agent)\n",
    "builder.add_node(\"conversation\", conv_agent)\n",
    "builder.add_node(\"manipulation\", manipulation_agent)\n",
    "builder.add_node(\"navigation\", navigation_agent)\n",
    "builder.add_node(\"vision\", vision_agent)\n",
    "\n",
    "# Define the edges of the graph\n",
    "builder.add_edge(START, \"planning\")\n",
    "\n",
    "# Define a condition function to route messages based on the planning agent's decision\n",
    "def route_to_agent(state):\n",
    "    # Get the last message from the assistant (which should be from the planning agent)\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if \"plan\" not in last_message.content:\n",
    "        return END\n",
    "    \n",
    "    # Try to extract the plan from the message content\n",
    "    # Use regex to extract JSON structure\n",
    "    pattern = r'\\[.*?\\]'\n",
    "    match = re.search(pattern, last_message.content, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            plan_data = literal_eval(match.group().replace(\"\\\\{\", \"{\").replace(\"\\\\}\", \"}\").replace(\"\\[\", \"[\").replace(\"\\]\", \"]\").replace(\"\\\\'\", \"'\"))\n",
    "            if len(plan_data) > 0:\n",
    "                # Get the first agent in the plan\n",
    "                next_step = plan_data[0]\n",
    "                next_agent = next_step[\"agent\"]\n",
    "                \n",
    "                # Update the original state with the modified plan (for future steps)\n",
    "                if plan_data:\n",
    "                    last_message.content = json.dumps(plan_data)\n",
    "                \n",
    "                # Return the next agent to call along with the new state\n",
    "                if next_agent in [\"conversation\", \"manipulation\", \"navigation\", \"vision\"]:\n",
    "                    return next_agent\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "    print(\"No valid plan found or unable to parse the plan.\")\n",
    "    \n",
    "    return END\n",
    "\n",
    "# Add conditional edges from planning to other agents\n",
    "builder.add_conditional_edges(\n",
    "    \"planning\",\n",
    "    route_to_agent,\n",
    "    {\n",
    "        \"conversation\": \"conversation\",\n",
    "        \"manipulation\": \"manipulation\",\n",
    "        \"navigation\": \"navigation\",\n",
    "        \"vision\": \"vision\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edges from other agents back to planning or to END\n",
    "# builder.add_edge(\"conversation\", \"planning\")\n",
    "# builder.add_edge(\"manipulation\", \"planning\")\n",
    "# builder.add_edge(\"navigation\", \"planning\")\n",
    "# builder.add_edge(\"vision\", \"planning\")\n",
    "\n",
    "builder.add_edge([\"conversation\", \"manipulation\", \"navigation\", \"vision\"], END)\n",
    "\n",
    "# Compile the graph\n",
    "react_graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b299b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={})]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={})]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mplanning\u001b[0m -> {'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='[{\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false}, {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-e2dfb813-d2c0-4a59-9be1-dec2848302e0')]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116'),\n",
      "              AIMessage(content='[{\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false}, {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-e2dfb813-d2c0-4a59-9be1-dec2848302e0')]}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 1 task for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mvision\u001b[0m -> {'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116'),\n",
      "              AIMessage(content='[{\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false}, {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-e2dfb813-d2c0-4a59-9be1-dec2848302e0')]}\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_c2wFhAirsr5RNO7ylNDPmBGf', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b'}, id='run-db73a109-348b-4a7b-a97e-f63c4c6eefcc', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_c2wFhAirsr5RNO7ylNDPmBGf', 'type': 'tool_call'}])]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116'),\n",
      "              AIMessage(content='[{\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false}, {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-e2dfb813-d2c0-4a59-9be1-dec2848302e0'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_c2wFhAirsr5RNO7ylNDPmBGf', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b'}, id='run-db73a109-348b-4a7b-a97e-f63c4c6eefcc', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_c2wFhAirsr5RNO7ylNDPmBGf', 'type': 'tool_call'}])]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Can you pick up the banana?\")]\n",
    "\n",
    "for chunk in react_graph.stream({\"messages\": messages}, stream_mode=\"messages\", debug=True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76118a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langgraph langchain_openai pydantic\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict, Literal, TypedDict, Any\n",
    "import json, re, os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import (\n",
    "    StateGraph, MessagesState, START, END\n",
    ")\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1.  Shared graph-state\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "class PlanState(MessagesState):                 # <- inherits \"messages\"\n",
    "    plan: List[Dict[str, Any]] = None             # remaining steps\n",
    "    current: Dict[str, Any] | None = None       # step being executed\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2.  The planning agent (supervisor)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "planner_llm = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0.1)\n",
    "\n",
    "PLAN_JSON_RE = re.compile(r\"\\[.*\\]\", re.DOTALL)\n",
    "\n",
    "def _extract_plan(text: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Robustly pull the JSON list out of the LLM reply.\"\"\"\n",
    "    m = PLAN_JSON_RE.search(text)\n",
    "    if not m:\n",
    "        raise ValueError(\"Planner returned no JSON plan\")\n",
    "    return json.loads(m.group())\n",
    "\n",
    "def planning_node(state: PlanState | dict) -> Command[Literal[\n",
    "        \"vision\", \"navigation\", \"manipulation\", \"conversation\", END]]:\n",
    "    \"\"\"\n",
    "    * If we already have a remaining plan, just pop the next step.\n",
    "    * Otherwise ask the planner LLM to create a fresh plan.\n",
    "    \"\"\"\n",
    "    print(f\"State: {state}\")\n",
    "    if type(state) == dict or state.plan is None:\n",
    "        user_prompt = state.messages[-1]              # last human message\n",
    "        raw_reply   = planner_llm.invoke(user_prompt)\n",
    "        plan        = _extract_plan(raw_reply.content)\n",
    "        state.update(messages=[raw_reply], plan=plan)\n",
    "\n",
    "    # pop next step\n",
    "    next_step = state.plan.pop(0)\n",
    "    state.current = next_step\n",
    "    next_agent = next_step[\"agent\"]\n",
    "\n",
    "    # when the list is empty after pop -> finish execution\n",
    "    return Command(\n",
    "        goto=next_agent if state.plan or next_agent else END,\n",
    "        update={\"plan\": state.plan, \"current\": state.current}\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3.  Tool definitions for each specialist\n",
    "# ---------------------------------------------------------------------------\n",
    "CONV_TOOLS = [\n",
    "    clarify,\n",
    "    speak\n",
    "]\n",
    "VISION_TOOLS = [\n",
    "    take_picture,\n",
    "    detect_objects,\n",
    "    recognize_text,\n",
    "    semantic_segmentation\n",
    "]\n",
    "MANIPULATION_TOOLS = [\n",
    "    move_arm,\n",
    "    move_joints,\n",
    "    pick_up_object\n",
    "]\n",
    "NAVIGATION_TOOLS = [\n",
    "    go_to_coordinates,\n",
    "    go_to_location,\n",
    "    rotate,\n",
    "    get_pose,\n",
    "    follow_person\n",
    "]\n",
    "\n",
    "def _make_agent(name: str, tools):\n",
    "    \"\"\"Returns (tool_calling_LLM, tool_node) for a specialist.\"\"\"\n",
    "    if not tools:                              # pure-LLM specialist\n",
    "        return ChatOpenAI(model=\"gpt-4o-mini\", temperature=0), None\n",
    "\n",
    "    model    = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind_tools(tools)\n",
    "    toolnode = ToolNode(tools)\n",
    "    return model, toolnode\n",
    "\n",
    "specs = {\n",
    "    \"vision\":        _make_agent(\"vision\",        VISION_TOOLS),\n",
    "    \"navigation\":    _make_agent(\"navigation\",    NAVIGATION_TOOLS),\n",
    "    \"manipulation\":  _make_agent(\"manipulation\",  MANIPULATION_TOOLS),\n",
    "    \"conversation\":  _make_agent(\"conversation\",  CONV_TOOLS),\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4.  Generic specialist node factory\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def specialist_factory(agent_name: str):\n",
    "    llm, tool_node = specs[agent_name]\n",
    "\n",
    "    def _node(state: PlanState) -> Command[Literal[\"planning\"]]:\n",
    "        \"\"\"Run the specialist on state.current['command'].\"\"\"\n",
    "        cmd = state.current[\"command\"]\n",
    "        # 1) Ask the LLM how it wants to fulfil the command\n",
    "        \n",
    "        ai_msg: AIMessage = llm.invoke(agent_sys_msg(module=agent_name) + cmd)\n",
    "        new_messages = [ai_msg]\n",
    "\n",
    "        # 2) If the LLM requested tool(s) -> run them\n",
    "        if ai_msg.tool_calls and tool_node is not None:\n",
    "            tool_out = tool_node.invoke({\"messages\": [ai_msg]})\n",
    "            new_messages.extend(tool_out[\"messages\"])\n",
    "\n",
    "        # 3) Update transcript and hand control back to planner\n",
    "        return Command(\n",
    "            goto=\"planning\",\n",
    "            update={\"messages\": new_messages}\n",
    "        )\n",
    "\n",
    "    return _node\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5.  Build the graph\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "builder = StateGraph(PlanState)\n",
    "\n",
    "# nodes\n",
    "builder.add_node(\"planning\", planning_node)\n",
    "for name in [\"vision\", \"navigation\", \"manipulation\", \"conversation\"]:\n",
    "    builder.add_node(name, specialist_factory(name))\n",
    "\n",
    "# start / end edges â€“ everything else is handled by Command-based gotos\n",
    "builder.add_edge(START, \"planning\")\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "109b5367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [('human',\n",
      "               'Please find the banana, drive to it and tell me once you '\n",
      "               'arrive.')]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('human', 'Please find the banana, drive to it and tell me once you arrive.')]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Please find the banana, drive to it and tell me once you arrive.', additional_kwargs={}, response_metadata={}, id='c9eecb86-9d28-4111-bda3-0d6a71f9de19')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mplanning\u001b[0m -> {'messages': [HumanMessage(content='Please find the banana, drive to it and tell me once you arrive.', additional_kwargs={}, response_metadata={}, id='c9eecb86-9d28-4111-bda3-0d6a71f9de19')]}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please find the banana, drive to it and tell me once you arrive.\n",
      "State: {'messages': [HumanMessage(content='Please find the banana, drive to it and tell me once you arrive.', additional_kwargs={}, response_metadata={}, id='c9eecb86-9d28-4111-bda3-0d6a71f9de19')]}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 6.  A quick demo run\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m example_question \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease find the banana, drive to it and tell me once you arrive.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m ]\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_question}, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# pretty print the last message for demo purposes\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     s[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2433\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2427\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2428\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2429\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2430\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2431\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2432\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2433\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2434\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2435\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2436\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2437\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2438\u001b[0m         ):\n\u001b[1;32m   2439\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2440\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2441\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/pregel/runner.py:153\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    151\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/utils/runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/utils/runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[18], line 45\u001b[0m, in \u001b[0;36mplanning_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(state) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m state\u001b[38;5;241m.\u001b[39mplan \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     user_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]              \u001b[38;5;66;03m# last human message\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     raw_reply   \u001b[38;5;241m=\u001b[39m planner_llm\u001b[38;5;241m.\u001b[39minvoke(user_prompt)\n\u001b[1;32m     47\u001b[0m     plan        \u001b[38;5;241m=\u001b[39m _extract_plan(raw_reply\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 6.  A quick demo run\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "example_question = [\n",
    "    (\"human\", \"Please find the banana, drive to it and tell me once you arrive.\")\n",
    "]\n",
    "\n",
    "for s in graph.stream({\"messages\": example_question}, stream_mode=\"values\", debug=True):\n",
    "    # pretty print the last message for demo purposes\n",
    "    s[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a84d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Can you pick up the banana?\")]\n",
    "\n",
    "for chunk in react_graph.stream({\"messages\": messages}, stream_mode=\"messages\", debug=True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe9403",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9018bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "agents_graph.py\n",
    "-----------------------------------------------------------------\n",
    "A LangGraph that orchestrates a Planner + 4 specialised agents\n",
    "(Vision, Navigation, Manipulation, Conversation).\n",
    "\n",
    "â€¢ The planner (systemâ€‘prompted) receives the user request first and\n",
    "  emits a JSON list like\n",
    "     [{\"agent\": \"vision\", \"command\": \"...\", \"parallel\": false}, â€¦]\n",
    "\n",
    "â€¢ Each specialist is an LLM able to call its own tools.\n",
    "  â€“ On **success** the tool result is appended to state.results.\n",
    "  â€“ On **failure** the specialist bounces straight back to the\n",
    "    planner, giving it a chance to reâ€‘plan.\n",
    "\n",
    "â€¢ When the last step in the plan succeeds, the whole accumulated\n",
    "  results array is handed to the planner so it can produce the\n",
    "  final answer for the user.\n",
    "\n",
    "Requires:  langgraphÂ â‰¥â€¯0.1  |  langchain_openai  |  pythonÂ â‰¥â€¯3.9\n",
    "-----------------------------------------------------------------\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict, Literal, Any\n",
    "import os, json, re, asyncio\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import (\n",
    "    StateGraph, START, END, MessagesState\n",
    ")\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d48d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 0.  SYSTEM PROMPTS\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "PLANNER_PROMPT = \"\"\"\\\n",
    "You are the **planner**.  \n",
    "Given the user's request, break the task into a minimal\n",
    "sequence of specialised agents.  Return **only** a JSON list,\n",
    "e.g.\n",
    "[\n",
    "  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\n",
    "  {\"agent\": \"navigation\", \"command\": \"drive to (x=42,y=7)\", \"parallel\": false}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "VISION_PROMPT = \"You are the **Vision** agent. Use your vision tools only.\"\n",
    "NAV_PROMPT    = \"You are the **Navigation** agent. Drive the robot.\"\n",
    "MANIP_PROMPT  = \"You are the **Manipulation** agent. Move robot arms.\"\n",
    "CONV_PROMPT   = \"You are the **Conversation** agent. Talk to the user.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8f238fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.  SHARED GRAPHâ€‘STATE\n",
    "# ---------------------------------------------------------------------\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "\n",
    "class PlanState(MessagesState, total=False):\n",
    "    plan:    List[Dict[str, Any]] = field(default_factory=list)\n",
    "    current: Optional[Dict[str, Any]] = None\n",
    "    results: List[str] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4dbec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.  THE PLANNER NODE\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "planner_llm = ChatOpenAI(\n",
    "    model       = \"gpt-4o-mini\",\n",
    "    temperature = 0,\n",
    "    streaming   = False\n",
    ").with_config({\"system_prompt\": PLANNER_PROMPT})\n",
    "\n",
    "_JSON_RE = re.compile(r\"\\[[\\s\\S]*\\]\")      # grab first JSON list\n",
    "\n",
    "def parse_plan(text: str) -> List[Dict[str, Any]]:\n",
    "    m = _JSON_RE.search(text)\n",
    "    if not m:\n",
    "        raise ValueError(\"Planner returned no JSON list\")\n",
    "    return json.loads(m.group())\n",
    "\n",
    "def planner_node(state: PlanState) -> Command[\n",
    "        Literal[\"vision\",\"navigation\",\"manipulation\",\"conversation\",END]]:\n",
    "    \"\"\"\n",
    "    â€¢ If state.plan is empty, ask LLM for a new one.\n",
    "    â€¢ Otherwise we have just finished all steps and must craft the\n",
    "      final answer.\n",
    "    \"\"\"\n",
    "    # â€”â€” 1) Need a new plan? â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "    if type(state) == dict or not state.plan:\n",
    "        # ask planner LLM (user message is always last)\n",
    "        reply: AIMessage = planner_llm.invoke(state.messages[-1])\n",
    "        plan = parse_plan(reply.content)\n",
    "\n",
    "        state.update(messages=[reply], plan=plan, results=[])\n",
    "\n",
    "        # pop first step\n",
    "        step = state.plan.pop(0)\n",
    "        state.current = step\n",
    "        return Command(\n",
    "            goto = step[\"agent\"],\n",
    "            update = {\n",
    "                \"plan\": state.plan,\n",
    "                \"current\": step,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    # â€”â€” 2) We have just completed **all** steps â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "    # Build a synthetic summary message and finish.\n",
    "    summary = \"\\n\".join(state.results)\n",
    "    final_msg = AIMessage(content=f\"All tools executed successfully:\\n{summary}\")\n",
    "    return Command(\n",
    "        goto   = END,\n",
    "        update = {\"messages\": [final_msg]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548f4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.  TOOLS\n",
    "# ---------------------------------------------------------------------\n",
    "from enum import Enum\n",
    "\n",
    "class LocationEnum(str, Enum):\n",
    "    kitchen = \"kitchen\"\n",
    "    living_room = \"living_room\"\n",
    "    bedroom = \"bedroom\"\n",
    "\n",
    "# Navigation tools\n",
    "@tool\n",
    "def go_to_coordinates(x: float, y: float):\n",
    "    \"\"\"\n",
    "    Move the robot to a specific set of coordinates.\n",
    "    Args:\n",
    "        x (float): The x coordinate.\n",
    "        y (float): The y coordinate.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If x or y is not a number.\n",
    "    Example:\n",
    "        >>> go_to_coordinates(10.5, 20.3)\n",
    "        {'status': 'success', 'message': 'Moved to coordinates (10.5, 20.3)'}\n",
    "    Example:\n",
    "        >>> go_to_coordinates(\"10.5\", 20.3)\n",
    "        ValueError: x and y must be numbers.\n",
    "    Example:\n",
    "        >>> go_to_coordinates(10.5, 20.3)\n",
    "        {'status': 'failure', 'message': 'Failed to move to coordinates (10.5, 20.3)'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving to coordinates ({x}, {y})\")\n",
    "    # Here you would add the code to move the robot to the specified coordinates\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved to coordinates ({x}, {y})\"}\n",
    "\n",
    "@tool\n",
    "def go_to_location(location_name: LocationEnum):\n",
    "    \"\"\"\n",
    "    Move the robot to a specific location.\n",
    "    Args:\n",
    "        location_name (LocationEnum): The name of the location.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If location_name is not a valid location.\n",
    "    Example:\n",
    "        >>> go_to_location(\"kitchen\")\n",
    "        {'status': 'success', 'message': 'Moved to location: kitchen'}\n",
    "    Example:\n",
    "        >>> go_to_location(\"garage\")\n",
    "        ValueError: location_name must be one of ['kitchen', 'living_room', 'bedroom'].\n",
    "    Example:\n",
    "        >>> go_to_location(\"living_room\")\n",
    "        {'status': 'failure', 'message': 'Failed to move to location: living_room'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving to location: {location_name}\")\n",
    "    # Here you would add the code to move the robot to the specified location\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved to location: {location_name}\"}\n",
    "\n",
    "@tool\n",
    "def rotate(angle: float):\n",
    "    \"\"\"\n",
    "    Rotate the robot to a specific angle.\n",
    "    Args:\n",
    "        angle (float): The angle to rotate to.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If angle is not a number.\n",
    "    Example:\n",
    "        >>> rotate(90)\n",
    "        {'status': 'success', 'message': 'Rotated to angle: 90'}\n",
    "    Example:\n",
    "        >>> rotate(\"90\")\n",
    "        ValueError: angle must be a number.\n",
    "    Example:\n",
    "        >>> rotate(90)\n",
    "        {'status': 'failure', 'message': 'Failed to rotate to angle: 90'}\n",
    "    \"\"\"\n",
    "    print(f\"Rotating to angle: {angle}\")\n",
    "    # Here you would add the code to rotate the robot to the specified angle\n",
    "    return {\"status\": \"success\", \"message\": f\"Rotated to angle: {angle}\"}\n",
    "\n",
    "@tool\n",
    "def get_pose():\n",
    "    \"\"\"\n",
    "    Get the current pose of the robot.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> get_pose()\n",
    "        {'status': 'success', 'message': 'Current pose: (x, y, theta)'}\n",
    "    Example:\n",
    "        >>> get_pose()\n",
    "        {'status': 'failure', 'message': 'Failed to get pose'}\n",
    "    \"\"\"\n",
    "    print(\"Getting current pose\")\n",
    "    # Here you would add the code to get the current pose of the robot\n",
    "    return {\"status\": \"success\", \"message\": \"Current pose: (x, y, theta)\"}\n",
    "\n",
    "@tool\n",
    "def follow_person():\n",
    "    \"\"\"\n",
    "    Follow a person.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> follow_person()\n",
    "        {'status': 'success', 'message': 'Following person'}\n",
    "    Example:\n",
    "        >>> follow_person()\n",
    "        {'status': 'failure', 'message': 'Failed to follow person'}\n",
    "    \"\"\"\n",
    "    print(\"Following person\")\n",
    "    # Here you would add the code to follow a person\n",
    "    return {\"status\": \"success\", \"message\": \"Following person\"}\n",
    "\n",
    "# Manipulation tools\n",
    "@tool\n",
    "def move_arm(x: float, y: float):\n",
    "    \"\"\"\n",
    "    Move the robot's arm to a specific position.\n",
    "    Args:\n",
    "        x (float): The x coordinate.\n",
    "        y (float): The y coordinate.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> move_arm(10.5, 20.3)\n",
    "        {'status': 'success', 'message': 'Moved arm to coordinates (10.5, 20.3)'}\n",
    "    Example:\n",
    "        >>> move_arm(\"10.5\", 20.3)\n",
    "        ValueError: x and y must be numbers.\n",
    "    Example:\n",
    "        >>> move_arm(10.5, 20.3)\n",
    "        {'status': 'failure', 'message': 'Failed to move arm to coordinates (10.5, 20.3)'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving arm to coordinates ({x}, {y})\")\n",
    "    # Here you would add the code to move the robot's arm to the specified coordinates\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved arm to coordinates ({x}, {y})\"}\n",
    "\n",
    "@tool\n",
    "def move_joints(joint_angles: list):\n",
    "    \"\"\"\n",
    "    Move the robot's joints to specific angles.\n",
    "    Args:\n",
    "        joint_angles (list): A list of joint angles.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> move_joints([30, 45, 60])\n",
    "        {'status': 'success', 'message': 'Moved joints to angles [30, 45, 60]'}\n",
    "    Example:\n",
    "        >>> move_joints(\"30, 45, 60\")\n",
    "        ValueError: joint_angles must be a list of numbers.\n",
    "    Example:\n",
    "        >>> move_joints([30, 45, 60])\n",
    "        {'status': 'failure', 'message': 'Failed to move joints to angles [30, 45, 60]'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving joints to angles {joint_angles}\")\n",
    "    # Here you would add the code to move the robot's joints to the specified angles\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved joints to angles {joint_angles}\"}\n",
    "\n",
    "@tool\n",
    "def pick_up_object(object_name: str):\n",
    "    \"\"\"\n",
    "    Pick up an object.\n",
    "    Args:\n",
    "        object_name (str): The name of the object to pick up.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> pick_up_object(\"box\")\n",
    "        {'status': 'success', 'message': 'Picked up object: box'}\n",
    "    Example:\n",
    "        >>> pick_up_object(123)\n",
    "        ValueError: object_name must be a string.\n",
    "    Example:\n",
    "        >>> pick_up_object(\"box\")\n",
    "        {'status': 'failure', 'message': 'Failed to pick up object: box'}\n",
    "    \"\"\"\n",
    "    print(f\"Picking up object: {object_name}\")\n",
    "    # Here you would add the code to pick up the specified object\n",
    "    return {\"status\": \"success\", \"message\": f\"Picked up object: {object_name}\"}\n",
    "\n",
    "@tool\n",
    "def press_button(button_name: str):\n",
    "    \"\"\"\n",
    "    Press a button.\n",
    "    Args:\n",
    "        button_name (str): The name of the button to press.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> press_button(\"start\")\n",
    "        {'status': 'success', 'message': 'Pressed button: start'}\n",
    "    Example:\n",
    "        >>> press_button(123)\n",
    "        ValueError: button_name must be a string.\n",
    "    Example:\n",
    "        >>> press_button(\"start\")\n",
    "        {'status': 'failure', 'message': 'Failed to press button: start'}\n",
    "    \"\"\"\n",
    "    print(f\"Pressing button: {button_name}\")\n",
    "    # Here you would add the code to press the specified button\n",
    "    return {\"status\": \"success\", \"message\": f\"Pressed button: {button_name}\"}\n",
    "\n",
    "# Vision tools\n",
    "@tool\n",
    "def take_picture():\n",
    "    \"\"\"\n",
    "    Take a picture.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> take_picture()\n",
    "        {'status': 'success', 'message': 'Picture taken'}\n",
    "    Example:\n",
    "        >>> take_picture()\n",
    "        {'status': 'failure', 'message': 'Failed to take picture'}\n",
    "    \"\"\"\n",
    "    print(\"Taking picture\")\n",
    "    # Here you would add the code to take a picture\n",
    "    return {\"status\": \"success\", \"message\": \"Picture taken\"}\n",
    "\n",
    "@tool\n",
    "def detect_objects(objects: List[str]):\n",
    "    \"\"\"\n",
    "    Detect objects in the environment.\n",
    "    Args:\n",
    "        objects (List[str]): A list of object names to detect.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> detect_objects([\"box\", \"chair\"])\n",
    "        {'status': 'success', 'message': 'Detected objects: box, chair'}\n",
    "    Example:\n",
    "        >>> detect_objects(\"box, chair\")\n",
    "        ValueError: objects must be a list of strings.\n",
    "    Example:\n",
    "        >>> detect_objects([\"box\", \"chair\"])\n",
    "        {'status': 'failure', 'message': 'Failed to detect objects: box, chair'}\n",
    "    \"\"\"\n",
    "    print(f\"Detecting objects: {objects}\")\n",
    "    # Here you would add the code to detect the specified objects\n",
    "    return {\"status\": \"success\", \"message\": f\"Detected objects: {', '.join(objects)}\"}\n",
    "\n",
    "@tool\n",
    "def recognize_text():\n",
    "    \"\"\"\n",
    "    Recognize text in the environment.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> recognize_text()\n",
    "        {'status': 'success', 'message': 'Recognized text: Hello, world!'}\n",
    "    Example:\n",
    "        >>> recognize_text()\n",
    "        {'status': 'failure', 'message': 'Failed to recognize text'}\n",
    "    \"\"\"\n",
    "    print(\"Recognizing text\")\n",
    "    # Here you would add the code to recognize text\n",
    "    return {\"status\": \"success\", \"message\": \"Recognized text: Hello, world!\"}\n",
    "\n",
    "@tool\n",
    "def semantic_segmentation():\n",
    "    \"\"\"\n",
    "    Perform semantic segmentation.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> semantic_segmentation()\n",
    "        {'status': 'success', 'message': 'Semantic segmentation completed'}\n",
    "    Example:\n",
    "        >>> semantic_segmentation()\n",
    "        {'status': 'failure', 'message': 'Failed to perform semantic segmentation'}\n",
    "    \"\"\"\n",
    "    print(\"Performing semantic segmentation\")\n",
    "    # Here you would add the code to perform semantic segmentation\n",
    "    return {\"status\": \"success\", \"message\": \"Semantic segmentation completed\"}\n",
    "\n",
    "# Conversational tools\n",
    "@tool\n",
    "def clarify(context: str, question: str):\n",
    "    \"\"\"\n",
    "    Clarify a question based on the context.\n",
    "    Args:\n",
    "        context (str): The context to clarify the question.\n",
    "        question (str): The question to clarify.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", \"Where is the robot?\")\n",
    "        {'status': 'success', 'message': 'The robot is in the kitchen.'}\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", 123)\n",
    "        ValueError: question must be a string.\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", \"Where is the robot?\")\n",
    "        {'status': 'failure', 'message': 'Failed to clarify the question.'}\n",
    "    \"\"\"\n",
    "    print(f\"Clarifying question: {question} based on context: {context}\")\n",
    "    # Here you would add the code to clarify the question based on the context\n",
    "    return {\"status\": \"success\", \"message\": f\"The robot is in the kitchen.\"}\n",
    "\n",
    "@tool\n",
    "def speak(text: str):\n",
    "    \"\"\"\n",
    "    Speak a given text.\n",
    "    Args:\n",
    "        text (str): The text to speak.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> speak(\"Hello, world!\")\n",
    "        {'status': 'success', 'message': 'Spoken text: Hello, world!'}\n",
    "    Example:\n",
    "        >>> speak(123)\n",
    "        ValueError: text must be a string.\n",
    "    Example:\n",
    "        >>> speak(\"Hello, world!\")\n",
    "        {'status': 'failure', 'message': 'Failed to speak text: Hello, world!'}\n",
    "    \"\"\"\n",
    "    print(f\"Speaking text: {text}\")\n",
    "    # Here you would add the code to speak the given text\n",
    "    return {\"status\": \"success\", \"message\": f\"Spoken text: {text}\"}\n",
    "\n",
    "\n",
    "\n",
    "CONV_TOOLS = [\n",
    "    clarify,\n",
    "    speak\n",
    "]\n",
    "VISION_TOOLS = [\n",
    "    take_picture,\n",
    "    detect_objects,\n",
    "    recognize_text,\n",
    "    semantic_segmentation\n",
    "]\n",
    "MANIPULATION_TOOLS = [\n",
    "    move_arm,\n",
    "    move_joints,\n",
    "    pick_up_object\n",
    "]\n",
    "NAVIGATION_TOOLS = [\n",
    "    go_to_coordinates,\n",
    "    go_to_location,\n",
    "    rotate,\n",
    "    get_pose,\n",
    "    follow_person\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf037733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 4.  SPECIALIST BUILD HELPER\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def make_specialist(\n",
    "        name: str,\n",
    "        system_prompt: str,\n",
    "        tools: list\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Returns a node function that:\n",
    "      â€¢ gets state.current[\"command\"]\n",
    "      â€¢ lets LLM decide which tool to call\n",
    "      â€¢ executes tool(s) via ToolNode\n",
    "      â€¢ on success â†’ store result, continue to next step or planner\n",
    "      â€¢ on failure â†’ go straight to planner\n",
    "    \"\"\"\n",
    "    base_llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                          temperature=0).with_config(\n",
    "                          {\"system_prompt\": system_prompt})\n",
    "    if tools:\n",
    "        llm = base_llm.bind_tools(tools)\n",
    "        tool_node = ToolNode(tools)\n",
    "    else:                   # conversation agent with no tools\n",
    "        llm, tool_node = base_llm, None\n",
    "\n",
    "    async def _node(state: PlanState) -> Command[\n",
    "            Literal[\"vision\",\"navigation\",\"manipulation\",\"conversation\",\"planning\"]]:\n",
    "\n",
    "        step_cmd = state.current[\"command\"]\n",
    "        ai_msg: AIMessage = llm.invoke(step_cmd)\n",
    "        new_msgs = [ai_msg]\n",
    "\n",
    "        # â€”â€” try to run requested tools â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "        success, tool_output = False, \"\"\n",
    "        if ai_msg.tool_calls and tool_node:\n",
    "            try:\n",
    "                out = tool_node.invoke({\"messages\": [ai_msg]})\n",
    "                new_msgs.extend(out[\"messages\"])\n",
    "                tool_output = out[\"messages\"][-1].content\n",
    "                success = tool_output and \"failed\" not in tool_output.lower()\n",
    "            except Exception as e:\n",
    "                tool_output = f\"Tool error: {e}\"\n",
    "\n",
    "        # â€”â€” decide next hop â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "        if not success:        # immediate feedback to planner\n",
    "            fail_msg = AIMessage(content=f\"{name} failed: {tool_output}\")\n",
    "            return Command(\n",
    "                goto   = \"planning\",\n",
    "                update = {\"messages\": new_msgs + [fail_msg]}\n",
    "            )\n",
    "\n",
    "        # success â†’ append result\n",
    "        state.results.append(f\"{name}: {tool_output}\")\n",
    "\n",
    "        if state.plan:        # still steps left â†’ next agent\n",
    "            nxt = state.plan.pop(0)\n",
    "            state.current = nxt\n",
    "            return Command(\n",
    "                goto   = nxt[\"agent\"],\n",
    "                update = {\n",
    "                    \"plan\": state.plan,\n",
    "                    \"current\": nxt,\n",
    "                    \"messages\": new_msgs\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # last step finished â†’ back to planner with results\n",
    "        return Command(\n",
    "            goto   = \"planning\",\n",
    "            update = {\"messages\": new_msgs}\n",
    "        )\n",
    "\n",
    "    return _node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4438254",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PlanState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 5.  BUILD GRAPH\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m builder \u001b[38;5;241m=\u001b[39m StateGraph(\u001b[43mPlanState\u001b[49m)\n\u001b[1;32m      7\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplanning\u001b[39m\u001b[38;5;124m\"\u001b[39m,       planner_node)\n\u001b[1;32m      8\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvision\u001b[39m\u001b[38;5;124m\"\u001b[39m,         make_specialist(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvision\u001b[39m\u001b[38;5;124m\"\u001b[39m,        VISION_PROMPT, VISION_TOOLS))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PlanState' is not defined"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5.  BUILD GRAPH\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "builder = StateGraph(PlanState)\n",
    "\n",
    "builder.add_node(\"planning\",       planner_node)\n",
    "builder.add_node(\"vision\",         make_specialist(\"vision\",        VISION_PROMPT, VISION_TOOLS))\n",
    "builder.add_node(\"navigation\",     make_specialist(\"navigation\",    NAV_PROMPT,    NAVIGATION_TOOLS))\n",
    "builder.add_node(\"manipulation\",   make_specialist(\"manipulation\",  MANIP_PROMPT,  MANIPULATION_TOOLS))\n",
    "builder.add_node(\"conversation\",   make_specialist(\"conversation\",  CONV_PROMPT,   CONV_TOOLS))\n",
    "\n",
    "builder.add_edge(START, \"planning\")           # entry point\n",
    "graph = builder.compile()\n",
    "\n",
    "# show graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c34b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### DEMO â€“ Ask the graph something ###\n",
      "\n",
      "â€” Find the banana, drive the robot to it and pick it up.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m user_message \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFind the banana, drive the robot to it and pick it up.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m stream \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [user_message]}, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m st \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# print the last message to show progress\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ€”\u001b[39m\u001b[38;5;124m\"\u001b[39m, st[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### DONE ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2461\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2455\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2456\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2457\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2458\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2461\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2462\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2463\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2464\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2465\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2466\u001b[0m         ):\n\u001b[1;32m   2467\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2468\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2469\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/pregel/runner.py:153\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    151\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/utils/runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/utils/runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[30], line 28\u001b[0m, in \u001b[0;36mplanner_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# â€”â€” 1) Need a new plan? â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(state) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mplan:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# ask planner LLM (user message is always last)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     reply: AIMessage \u001b[38;5;241m=\u001b[39m planner_llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     29\u001b[0m     plan \u001b[38;5;241m=\u001b[39m parse_plan(reply\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     31\u001b[0m     state\u001b[38;5;241m.\u001b[39mupdate(messages\u001b[38;5;241m=\u001b[39m[reply], plan\u001b[38;5;241m=\u001b[39mplan, results\u001b[38;5;241m=\u001b[39m[])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6.  QUICK DEMO\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"\\n### DEMO â€“ Ask the graph something ###\\n\")\n",
    "    user_message = (\"human\",\n",
    "        \"Find the banana, drive the robot to it and pick it up.\")\n",
    "    stream = graph.stream({\"messages\": [user_message]}, stream_mode=\"values\")\n",
    "\n",
    "    for st in stream:\n",
    "        # print the last message to show progress\n",
    "        print(\"â€”\", st[\"messages\"][-1].content)\n",
    "\n",
    "    print(\"\\n### DONE ###\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcfefade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "agents_graph_simple.py\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Hubâ€‘andâ€‘spoke agent graph for controlling a robot.\n",
    "Planner (hub) decides the next specialist (spoke) step.\n",
    "Specialists never talk to each otherâ€”only to the planner.\n",
    "This is a trimmedâ€‘down, selfâ€‘contained version of your original\n",
    "script that compiles and keeps the same behaviour.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import json, re\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Literal\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273ed9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SYSTEM PROMPTS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PLANNER_PROMPT = \"\"\"You are the PLANNER in charge of orchestrating a robot with four\n",
    "specialists: vision, navigation, manipulation and conversation.\n",
    "Figure out a short ordered python list of steps (JSON only!) that the robot\n",
    "must execute to complete the user request.\n",
    "Return ONLY a python array\n",
    "Example:\n",
    "[\n",
    "  {\"agent\": \"vision\",       \"command\": \"locate the banana\",          \"parallel\": false},\n",
    "  {\"agent\": \"navigation\",   \"command\": \"drive to 42 7\",               \"parallel\": false},\n",
    "  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\",           \"parallel\": false},\n",
    "  {\"agent\": \"conversation\", \"command\": \"tell the user the job is done\",\"parallel\": false}\n",
    "]\n",
    "\n",
    "Remember to output a python list, otherwise the robot won't understand it.\n",
    "\"\"\"\n",
    "\n",
    "VISION_PROMPT = \"You are the VISION specialist. Use vision tools only to locate objects.\"\n",
    "NAV_PROMPT    = \"You are the NAVIGATION specialist. Drive the robot accurately.\"\n",
    "MANIP_PROMPT  = \"You are the MANIPULATION specialist. Pick up or drop items.\"\n",
    "CONV_PROMPT   = \"You are the CONVERSATION specialist. Speak with the human only.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f6ed97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SHARED GRAPH STATE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    \"\"\"Everything nodes need to know is in here.\"\"\"\n",
    "    messages: List[Any] = field(default_factory=list)          # full chat history\n",
    "    plan:     List[Dict[str, Any]] = field(default_factory=list)  # remaining steps\n",
    "    current:  Dict[str, Any] | None = None                     # step in progress\n",
    "    results:  List[str] = field(default_factory=list)          # humanâ€‘friendly log\n",
    "    n_executed: int = 0                                         # number of steps executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "072a79a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print((not [] and type([]) != list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fcf7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.  THE PLANNER NODE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "planner_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1\n",
    "                         ).with_config({\"system_prompt\": PLANNER_PROMPT})\n",
    "# planner_llm = planner_llm.bind(response_format={\"type\": \"json_object\"})\n",
    "\n",
    "_JSON_RE = re.compile(r\"\\[[\\s\\S]*]\")\n",
    "\n",
    "def _parse_plan(text: str) -> List[Dict[str, Any]]:\n",
    "    m = _JSON_RE.search(text)\n",
    "    if not m:\n",
    "        raise ValueError(\"Planner produced no JSON list\")\n",
    "    return json.loads(m.group())\n",
    "\n",
    "def planner_node(state: AgentState) -> Command[\n",
    "        Literal[\"vision\", \"navigation\", \"manipulation\", \"conversation\", END]]:\n",
    "    \"\"\"Create a plan if needed, otherwise dispatch next step or finish.\"\"\"\n",
    "    updates: Dict[str, Any] = {}\n",
    "\n",
    "    # Need a plan? â€” ask the planner LLM\n",
    "    if not state.plan and state.n_executed == 0:\n",
    "        llm_reply: AIMessage = planner_llm.invoke([PLANNER_PROMPT] + [state.messages[-1]])\n",
    "        print(f\"llm reply: {llm_reply.content}\")\n",
    "        plan = _parse_plan(llm_reply.content)\n",
    "        updates[\"plan\"]     = plan\n",
    "        updates[\"messages\"] = state.messages + [llm_reply]\n",
    "\n",
    "    # Still have steps? â€” send the next one to its specialist\n",
    "    plan = updates.get(\"plan\", state.plan)\n",
    "    if plan:\n",
    "        step = plan.pop(0)\n",
    "        updates.update({\"plan\": plan, \"current\": step})\n",
    "        print(f\"executing next step: {step}\")\n",
    "        return Command(goto=step[\"agent\"], update=updates)\n",
    "    else:\n",
    "        print(f\"No more steps in the plan.\")\n",
    "\n",
    "    # Nothing left â€” summarise & END\n",
    "    summary = \"\\n\".join(state.results) or \"Nothing executed.\"\n",
    "    final_msg = AIMessage(content=f\"Here is what happened:\\n{summary}\")\n",
    "    updates[\"messages\"] = state.messages + [final_msg]\n",
    "    return Command(goto=END, update=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47b0e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.  VERY SMALL DEMO TOOLS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from enum import Enum\n",
    "\n",
    "class LocationEnum(str, Enum):\n",
    "    kitchen = \"kitchen\"\n",
    "    living_room = \"living_room\"\n",
    "    bedroom = \"bedroom\"\n",
    "\n",
    "# Navigation tools\n",
    "@tool\n",
    "def go_to_coordinates(x: float, y: float):\n",
    "    \"\"\"\n",
    "    Move the robot to a specific set of coordinates.\n",
    "    Args:\n",
    "        x (float): The x coordinate.\n",
    "        y (float): The y coordinate.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If x or y is not a number.\n",
    "    Example:\n",
    "        >>> go_to_coordinates(10.5, 20.3)\n",
    "        {'status': 'success', 'message': 'Moved to coordinates (10.5, 20.3)'}\n",
    "    Example:\n",
    "        >>> go_to_coordinates(\"10.5\", 20.3)\n",
    "        ValueError: x and y must be numbers.\n",
    "    Example:\n",
    "        >>> go_to_coordinates(10.5, 20.3)\n",
    "        {'status': 'failure', 'message': 'Failed to move to coordinates (10.5, 20.3)'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving to coordinates ({x}, {y})\")\n",
    "    # Here you would add the code to move the robot to the specified coordinates\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved to coordinates ({x}, {y})\"}\n",
    "\n",
    "@tool\n",
    "def go_to_location(location_name: LocationEnum):\n",
    "    \"\"\"\n",
    "    Move the robot to a specific location.\n",
    "    Args:\n",
    "        location_name (LocationEnum): The name of the location.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If location_name is not a valid location.\n",
    "    Example:\n",
    "        >>> go_to_location(\"kitchen\")\n",
    "        {'status': 'success', 'message': 'Moved to location: kitchen'}\n",
    "    Example:\n",
    "        >>> go_to_location(\"garage\")\n",
    "        ValueError: location_name must be one of ['kitchen', 'living_room', 'bedroom'].\n",
    "    Example:\n",
    "        >>> go_to_location(\"living_room\")\n",
    "        {'status': 'failure', 'message': 'Failed to move to location: living_room'}\n",
    "    \"\"\"\n",
    "    # Here you would add the code to move the robot to the specified location\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved to location: {location_name}\"}\n",
    "\n",
    "@tool\n",
    "def rotate(angle: float):\n",
    "    \"\"\"\n",
    "    Rotate the robot to a specific angle.\n",
    "    Args:\n",
    "        angle (float): The angle to rotate to.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If angle is not a number.\n",
    "    Example:\n",
    "        >>> rotate(90)\n",
    "        {'status': 'success', 'message': 'Rotated to angle: 90'}\n",
    "    Example:\n",
    "        >>> rotate(\"90\")\n",
    "        ValueError: angle must be a number.\n",
    "    Example:\n",
    "        >>> rotate(90)\n",
    "        {'status': 'failure', 'message': 'Failed to rotate to angle: 90'}\n",
    "    \"\"\"\n",
    "    print(f\"Rotating to angle: {angle}\")\n",
    "    # Here you would add the code to rotate the robot to the specified angle\n",
    "    return {\"status\": \"success\", \"message\": f\"Rotated to angle: {angle}\"}\n",
    "\n",
    "@tool\n",
    "def get_pose():\n",
    "    \"\"\"\n",
    "    Get the current pose of the robot.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> get_pose()\n",
    "        {'status': 'success', 'message': 'Current pose: (x, y, theta)'}\n",
    "    Example:\n",
    "        >>> get_pose()\n",
    "        {'status': 'failure', 'message': 'Failed to get pose'}\n",
    "    \"\"\"\n",
    "    print(\"Getting current pose\")\n",
    "    # Here you would add the code to get the current pose of the robot\n",
    "    return {\"status\": \"success\", \"message\": \"Current pose: (x, y, theta)\"}\n",
    "\n",
    "@tool\n",
    "def follow_person():\n",
    "    \"\"\"\n",
    "    Follow a person.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> follow_person()\n",
    "        {'status': 'success', 'message': 'Following person'}\n",
    "    Example:\n",
    "        >>> follow_person()\n",
    "        {'status': 'failure', 'message': 'Failed to follow person'}\n",
    "    \"\"\"\n",
    "    print(\"Following person\")\n",
    "    # Here you would add the code to follow a person\n",
    "    return {\"status\": \"success\", \"message\": \"Following person\"}\n",
    "\n",
    "# Manipulation tools\n",
    "@tool\n",
    "def move_arm(x: float, y: float):\n",
    "    \"\"\"\n",
    "    Move the robot's arm to a specific position.\n",
    "    Args:\n",
    "        x (float): The x coordinate.\n",
    "        y (float): The y coordinate.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> move_arm(10.5, 20.3)\n",
    "        {'status': 'success', 'message': 'Moved arm to coordinates (10.5, 20.3)'}\n",
    "    Example:\n",
    "        >>> move_arm(\"10.5\", 20.3)\n",
    "        ValueError: x and y must be numbers.\n",
    "    Example:\n",
    "        >>> move_arm(10.5, 20.3)\n",
    "        {'status': 'failure', 'message': 'Failed to move arm to coordinates (10.5, 20.3)'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving arm to coordinates ({x}, {y})\")\n",
    "    # Here you would add the code to move the robot's arm to the specified coordinates\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved arm to coordinates ({x}, {y})\"}\n",
    "\n",
    "@tool\n",
    "def move_joints(joint_angles: list):\n",
    "    \"\"\"\n",
    "    Move the robot's joints to specific angles.\n",
    "    Args:\n",
    "        joint_angles (list): A list of joint angles.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> move_joints([30, 45, 60])\n",
    "        {'status': 'success', 'message': 'Moved joints to angles [30, 45, 60]'}\n",
    "    Example:\n",
    "        >>> move_joints(\"30, 45, 60\")\n",
    "        ValueError: joint_angles must be a list of numbers.\n",
    "    Example:\n",
    "        >>> move_joints([30, 45, 60])\n",
    "        {'status': 'failure', 'message': 'Failed to move joints to angles [30, 45, 60]'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving joints to angles {joint_angles}\")\n",
    "    # Here you would add the code to move the robot's joints to the specified angles\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved joints to angles {joint_angles}\"}\n",
    "\n",
    "@tool\n",
    "def pick_up_object(object_name: str):\n",
    "    \"\"\"\n",
    "    Pick up an object.\n",
    "    Args:\n",
    "        object_name (str): The name of the object to pick up.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> pick_up_object(\"box\")\n",
    "        {'status': 'success', 'message': 'Picked up object: box'}\n",
    "    Example:\n",
    "        >>> pick_up_object(123)\n",
    "        ValueError: object_name must be a string.\n",
    "    Example:\n",
    "        >>> pick_up_object(\"box\")\n",
    "        {'status': 'failure', 'message': 'Failed to pick up object: box'}\n",
    "    \"\"\"\n",
    "    print(f\"Picking up object: {object_name}\")\n",
    "    # Here you would add the code to pick up the specified object\n",
    "    return {\"status\": \"success\", \"message\": f\"Picked up object: {object_name}\"}\n",
    "\n",
    "@tool\n",
    "def press_button(button_name: str):\n",
    "    \"\"\"\n",
    "    Press a button.\n",
    "    Args:\n",
    "        button_name (str): The name of the button to press.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> press_button(\"start\")\n",
    "        {'status': 'success', 'message': 'Pressed button: start'}\n",
    "    Example:\n",
    "        >>> press_button(123)\n",
    "        ValueError: button_name must be a string.\n",
    "    Example:\n",
    "        >>> press_button(\"start\")\n",
    "        {'status': 'failure', 'message': 'Failed to press button: start'}\n",
    "    \"\"\"\n",
    "    print(f\"Pressing button: {button_name}\")\n",
    "    # Here you would add the code to press the specified button\n",
    "    return {\"status\": \"success\", \"message\": f\"Pressed button: {button_name}\"}\n",
    "\n",
    "# Vision tools\n",
    "@tool\n",
    "def take_picture():\n",
    "    \"\"\"\n",
    "    Take a picture.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> take_picture()\n",
    "        {'status': 'success', 'message': 'Picture taken'}\n",
    "    Example:\n",
    "        >>> take_picture()\n",
    "        {'status': 'failure', 'message': 'Failed to take picture'}\n",
    "    \"\"\"\n",
    "    print(\"Taking picture\")\n",
    "    # Here you would add the code to take a picture\n",
    "    return {\"status\": \"success\", \"message\": \"Picture taken\"}\n",
    "\n",
    "@tool\n",
    "def detect_objects(objects: List[str]):\n",
    "    \"\"\"\n",
    "    Detect objects in the environment.\n",
    "    Args:\n",
    "        objects (List[str]): A list of object names to detect.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> detect_objects([\"box\", \"chair\"])\n",
    "        {'status': 'success', 'message': 'Detected objects: box, chair'}\n",
    "    Example:\n",
    "        >>> detect_objects(\"box, chair\")\n",
    "        ValueError: objects must be a list of strings.\n",
    "    Example:\n",
    "        >>> detect_objects([\"box\", \"chair\"])\n",
    "        {'status': 'failure', 'message': 'Failed to detect objects: box, chair'}\n",
    "    \"\"\"\n",
    "    print(f\"Detecting objects: {objects}\")\n",
    "    # Here you would add the code to detect the specified objects\n",
    "    return {\"status\": \"success\", \"message\": f\"Detected objects: {', '.join(objects)} are in the kitchen\"}\n",
    "\n",
    "@tool\n",
    "def recognize_text():\n",
    "    \"\"\"\n",
    "    Recognize text in the environment.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> recognize_text()\n",
    "        {'status': 'success', 'message': 'Recognized text: Hello, world!'}\n",
    "    Example:\n",
    "        >>> recognize_text()\n",
    "        {'status': 'failure', 'message': 'Failed to recognize text'}\n",
    "    \"\"\"\n",
    "    print(\"Recognizing text\")\n",
    "    # Here you would add the code to recognize text\n",
    "    return {\"status\": \"success\", \"message\": \"Recognized text: Hello, world!\"}\n",
    "\n",
    "@tool\n",
    "def semantic_segmentation():\n",
    "    \"\"\"\n",
    "    Perform semantic segmentation.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> semantic_segmentation()\n",
    "        {'status': 'success', 'message': 'Semantic segmentation completed'}\n",
    "    Example:\n",
    "        >>> semantic_segmentation()\n",
    "        {'status': 'failure', 'message': 'Failed to perform semantic segmentation'}\n",
    "    \"\"\"\n",
    "    print(\"Performing semantic segmentation\")\n",
    "    # Here you would add the code to perform semantic segmentation\n",
    "    return {\"status\": \"success\", \"message\": \"Semantic segmentation completed\"}\n",
    "\n",
    "# Conversational tools\n",
    "@tool\n",
    "def clarify(context: str, question: str):\n",
    "    \"\"\"\n",
    "    Clarify a question based on the context.\n",
    "    Args:\n",
    "        context (str): The context to clarify the question.\n",
    "        question (str): The question to clarify.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", \"Where is the robot?\")\n",
    "        {'status': 'success', 'message': 'The robot is in the kitchen.'}\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", 123)\n",
    "        ValueError: question must be a string.\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", \"Where is the robot?\")\n",
    "        {'status': 'failure', 'message': 'Failed to clarify the question.'}\n",
    "    \"\"\"\n",
    "    print(f\"Clarifying question: {question} based on context: {context}\")\n",
    "    # Here you would add the code to clarify the question based on the context\n",
    "    return {\"status\": \"success\", \"message\": f\"The robot is in the kitchen.\"}\n",
    "\n",
    "@tool\n",
    "def speak(text: str):\n",
    "    \"\"\"\n",
    "    Speak a given text.\n",
    "    Args:\n",
    "        text (str): The text to speak.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> speak(\"Hello, world!\")\n",
    "        {'status': 'success', 'message': 'Spoken text: Hello, world!'}\n",
    "    Example:\n",
    "        >>> speak(123)\n",
    "        ValueError: text must be a string.\n",
    "    Example:\n",
    "        >>> speak(\"Hello, world!\")\n",
    "        {'status': 'failure', 'message': 'Failed to speak text: Hello, world!'}\n",
    "    \"\"\"\n",
    "    print(f\"Speaking text: {text}\")\n",
    "    # Here you would add the code to speak the given text\n",
    "    return {\"status\": \"success\", \"message\": f\"Spoken text: {text}\"}\n",
    "\n",
    "\n",
    "\n",
    "CONV_TOOLS = [\n",
    "    clarify,\n",
    "    speak\n",
    "]\n",
    "VISION_TOOLS = [\n",
    "    take_picture,\n",
    "    detect_objects,\n",
    "    recognize_text,\n",
    "    semantic_segmentation\n",
    "]\n",
    "MANIPULATION_TOOLS = [\n",
    "    move_arm,\n",
    "    move_joints,\n",
    "    pick_up_object\n",
    "]\n",
    "NAVIGATION_TOOLS = [\n",
    "    go_to_coordinates,\n",
    "    go_to_location,\n",
    "    rotate,\n",
    "    get_pose,\n",
    "    follow_person\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b98a56fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.  SPECIALIST FACTORY  (each one always hands control back to planning)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def make_specialist(name: str, system_prompt: str, tools: list):\n",
    "    base_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1\n",
    "                          ).with_config({\"system_prompt\": system_prompt})\n",
    "\n",
    "    llm = base_llm.bind_tools(tools) if tools else base_llm\n",
    "    tool_node = ToolNode(tools) if tools else None\n",
    "\n",
    "    def _node(state: AgentState) -> Command[Literal[\"planning\"]]:\n",
    "        cmd_text = \"\\nNew message:\\n\".join(([\"Passed results:\\n\"] + state.results + [state.current[\"command\"]]))\n",
    "        # print(f\"cmd_text: {cmd_text}\")\n",
    "        # print(f\"state.results: {state.results}\")\n",
    "        ai_msg: AIMessage = llm.invoke(cmd_text)\n",
    "        msgs = state.messages + [ai_msg]\n",
    "\n",
    "        success, result = False, \"\"\n",
    "        if ai_msg.tool_calls and tool_node:\n",
    "            try:\n",
    "                out = tool_node.invoke({\"messages\": [ai_msg]})\n",
    "                tool_msgs = out[\"messages\"]\n",
    "                msgs.extend(tool_msgs)\n",
    "                result = tool_msgs[-1].content\n",
    "                success = \"failed\" not in result.lower()\n",
    "            except Exception as e:\n",
    "                result = f\"tool error: {e}\"\n",
    "\n",
    "        # Record what happened and decide whether to reâ€‘plan\n",
    "        if success:\n",
    "            results = state.results + [f\"{name}: {result}\"]\n",
    "            plan = state.plan\n",
    "            n_executed = state.n_executed + 1\n",
    "        else:\n",
    "            results = state.results\n",
    "            plan = []  # Force the planner to produce a new plan\n",
    "            msgs.append(AIMessage(content=f\"{name} FAILED: {result}\"))\n",
    "\n",
    "        update = {\"messages\": msgs, \"results\": results, \"plan\": plan, \"n_executed\": n_executed}\n",
    "        return Command(goto=\"planning\", update=update)\n",
    "\n",
    "    return _node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3c9d43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6.  BUILD THE GRAPH\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"planning\",     planner_node)\n",
    "builder.add_node(\"vision\",       make_specialist(\"vision\",       VISION_PROMPT, VISION_TOOLS))\n",
    "builder.add_node(\"navigation\",   make_specialist(\"navigation\",   NAV_PROMPT,    NAVIGATION_TOOLS))\n",
    "builder.add_node(\"manipulation\", make_specialist(\"manipulation\", MANIP_PROMPT,  MANIPULATION_TOOLS))\n",
    "builder.add_node(\"conversation\", make_specialist(\"conversation\", CONV_PROMPT,   CONV_TOOLS))\n",
    "\n",
    "builder.add_edge(START, \"planning\")  # the single required edge\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daaddfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [('human', 'Find the banana.')]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('human', 'Find the banana.')]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [('human', 'Find the banana.')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mplanning\u001b[0m -> AgentState(messages=[('human', 'Find the banana.')],\n",
      "           plan=[],\n",
      "           current=None,\n",
      "           results=[],\n",
      "           n_executed=0)\n",
      "llm reply: ```python\n",
      "[\n",
      "  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\n",
      "  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\n",
      "  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\n",
      "  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\n",
      "]\n",
      "```\n",
      "executing next step: {'agent': 'vision', 'command': 'locate the banana', 'parallel': False}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 3 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mplan\u001b[0m -> [{'agent': 'navigation',\n",
      "  'command': 'navigate to the banana',\n",
      "  'parallel': False},\n",
      " {'agent': 'manipulation', 'command': 'pick up the banana', 'parallel': False},\n",
      " {'agent': 'conversation',\n",
      "  'command': 'inform the user that the banana has been found',\n",
      "  'parallel': False}]\n",
      "- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('human', 'Find the banana.'),\n",
      " AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "- \u001b[33;1m\u001b[1;3mcurrent\u001b[0m -> {'agent': 'vision', 'command': 'locate the banana', 'parallel': False}\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'current': {'agent': 'vision',\n",
      "             'command': 'locate the banana',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
      " 'plan': [{'agent': 'navigation',\n",
      "           'command': 'navigate to the banana',\n",
      "           'parallel': False},\n",
      "          {'agent': 'manipulation',\n",
      "           'command': 'pick up the banana',\n",
      "           'parallel': False},\n",
      "          {'agent': 'conversation',\n",
      "           'command': 'inform the user that the banana has been found',\n",
      "           'parallel': False}]}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 1 task for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mvision\u001b[0m -> AgentState(messages=[('human', 'Find the banana.'),\n",
      "                     AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
      "           plan=[{'agent': 'navigation',\n",
      "                  'command': 'navigate to the banana',\n",
      "                  'parallel': False},\n",
      "                 {'agent': 'manipulation',\n",
      "                  'command': 'pick up the banana',\n",
      "                  'parallel': False},\n",
      "                 {'agent': 'conversation',\n",
      "                  'command': 'inform the user that the banana has been found',\n",
      "                  'parallel': False}],\n",
      "           current={'agent': 'vision',\n",
      "                    'command': 'locate the banana',\n",
      "                    'parallel': False},\n",
      "           results=[],\n",
      "           n_executed=0)\n",
      "Detecting objects: ['banana']\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 4 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('human', 'Find the banana.'),\n",
      " AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC')]\n",
      "- \u001b[33;1m\u001b[1;3mresults\u001b[0m -> ['vision: {\"status\": \"success\", \"message\": \"Detected objects: banana are in '\n",
      " 'the kitchen\"}']\n",
      "- \u001b[33;1m\u001b[1;3mplan\u001b[0m -> [{'agent': 'navigation',\n",
      "  'command': 'navigate to the banana',\n",
      "  'parallel': False},\n",
      " {'agent': 'manipulation', 'command': 'pick up the banana', 'parallel': False},\n",
      " {'agent': 'conversation',\n",
      "  'command': 'inform the user that the banana has been found',\n",
      "  'parallel': False}]\n",
      "- \u001b[33;1m\u001b[1;3mn_executed\u001b[0m -> 1\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'current': {'agent': 'vision',\n",
      "             'command': 'locate the banana',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC')],\n",
      " 'n_executed': 1,\n",
      " 'plan': [{'agent': 'navigation',\n",
      "           'command': 'navigate to the banana',\n",
      "           'parallel': False},\n",
      "          {'agent': 'manipulation',\n",
      "           'command': 'pick up the banana',\n",
      "           'parallel': False},\n",
      "          {'agent': 'conversation',\n",
      "           'command': 'inform the user that the banana has been found',\n",
      "           'parallel': False}],\n",
      " 'results': ['vision: {\"status\": \"success\", \"message\": \"Detected objects: '\n",
      "             'banana are in the kitchen\"}']}\n",
      "\u001b[36;1m\u001b[1;3m[3:tasks]\u001b[0m \u001b[1mStarting 1 task for step 3:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mplanning\u001b[0m -> AgentState(messages=[('human', 'Find the banana.'),\n",
      "                     AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC')],\n",
      "           plan=[{'agent': 'navigation',\n",
      "                  'command': 'navigate to the banana',\n",
      "                  'parallel': False},\n",
      "                 {'agent': 'manipulation',\n",
      "                  'command': 'pick up the banana',\n",
      "                  'parallel': False},\n",
      "                 {'agent': 'conversation',\n",
      "                  'command': 'inform the user that the banana has been found',\n",
      "                  'parallel': False}],\n",
      "           current={'agent': 'vision',\n",
      "                    'command': 'locate the banana',\n",
      "                    'parallel': False},\n",
      "           results=['vision: {\"status\": \"success\", \"message\": \"Detected '\n",
      "                    'objects: banana are in the kitchen\"}'],\n",
      "           n_executed=1)\n",
      "executing next step: {'agent': 'navigation', 'command': 'navigate to the banana', 'parallel': False}\n",
      "\u001b[36;1m\u001b[1;3m[3:writes]\u001b[0m \u001b[1mFinished step 3 with writes to 2 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mplan\u001b[0m -> [{'agent': 'manipulation', 'command': 'pick up the banana', 'parallel': False},\n",
      " {'agent': 'conversation',\n",
      "  'command': 'inform the user that the banana has been found',\n",
      "  'parallel': False}]\n",
      "- \u001b[33;1m\u001b[1;3mcurrent\u001b[0m -> {'agent': 'navigation', 'command': 'navigate to the banana', 'parallel': False}\n",
      "\u001b[36;1m\u001b[1;3m[3:checkpoint]\u001b[0m \u001b[1mState at the end of step 3:\n",
      "\u001b[0m{'current': {'agent': 'navigation',\n",
      "             'command': 'navigate to the banana',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC')],\n",
      " 'n_executed': 1,\n",
      " 'plan': [{'agent': 'manipulation',\n",
      "           'command': 'pick up the banana',\n",
      "           'parallel': False},\n",
      "          {'agent': 'conversation',\n",
      "           'command': 'inform the user that the banana has been found',\n",
      "           'parallel': False}],\n",
      " 'results': ['vision: {\"status\": \"success\", \"message\": \"Detected objects: '\n",
      "             'banana are in the kitchen\"}']}\n",
      "\u001b[36;1m\u001b[1;3m[4:tasks]\u001b[0m \u001b[1mStarting 1 task for step 4:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mnavigation\u001b[0m -> AgentState(messages=[('human', 'Find the banana.'),\n",
      "                     AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC')],\n",
      "           plan=[{'agent': 'manipulation',\n",
      "                  'command': 'pick up the banana',\n",
      "                  'parallel': False},\n",
      "                 {'agent': 'conversation',\n",
      "                  'command': 'inform the user that the banana has been found',\n",
      "                  'parallel': False}],\n",
      "           current={'agent': 'navigation',\n",
      "                    'command': 'navigate to the banana',\n",
      "                    'parallel': False},\n",
      "           results=['vision: {\"status\": \"success\", \"message\": \"Detected '\n",
      "                    'objects: banana are in the kitchen\"}'],\n",
      "           n_executed=1)\n",
      "\u001b[36;1m\u001b[1;3m[4:writes]\u001b[0m \u001b[1mFinished step 4 with writes to 4 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('human', 'Find the banana.'),\n",
      " AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk')]\n",
      "- \u001b[33;1m\u001b[1;3mresults\u001b[0m -> ['vision: {\"status\": \"success\", \"message\": \"Detected objects: banana are in '\n",
      " 'the kitchen\"}',\n",
      " 'navigation: {\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}']\n",
      "- \u001b[33;1m\u001b[1;3mplan\u001b[0m -> [{'agent': 'manipulation', 'command': 'pick up the banana', 'parallel': False},\n",
      " {'agent': 'conversation',\n",
      "  'command': 'inform the user that the banana has been found',\n",
      "  'parallel': False}]\n",
      "- \u001b[33;1m\u001b[1;3mn_executed\u001b[0m -> 2\n",
      "\u001b[36;1m\u001b[1;3m[4:checkpoint]\u001b[0m \u001b[1mState at the end of step 4:\n",
      "\u001b[0m{'current': {'agent': 'navigation',\n",
      "             'command': 'navigate to the banana',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk')],\n",
      " 'n_executed': 2,\n",
      " 'plan': [{'agent': 'manipulation',\n",
      "           'command': 'pick up the banana',\n",
      "           'parallel': False},\n",
      "          {'agent': 'conversation',\n",
      "           'command': 'inform the user that the banana has been found',\n",
      "           'parallel': False}],\n",
      " 'results': ['vision: {\"status\": \"success\", \"message\": \"Detected objects: '\n",
      "             'banana are in the kitchen\"}',\n",
      "             'navigation: {\"status\": \"success\", \"message\": \"Moved to location: '\n",
      "             'kitchen\"}']}\n",
      "\u001b[36;1m\u001b[1;3m[5:tasks]\u001b[0m \u001b[1mStarting 1 task for step 5:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mplanning\u001b[0m -> AgentState(messages=[('human', 'Find the banana.'),\n",
      "                     AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk')],\n",
      "           plan=[{'agent': 'manipulation',\n",
      "                  'command': 'pick up the banana',\n",
      "                  'parallel': False},\n",
      "                 {'agent': 'conversation',\n",
      "                  'command': 'inform the user that the banana has been found',\n",
      "                  'parallel': False}],\n",
      "           current={'agent': 'navigation',\n",
      "                    'command': 'navigate to the banana',\n",
      "                    'parallel': False},\n",
      "           results=['vision: {\"status\": \"success\", \"message\": \"Detected '\n",
      "                    'objects: banana are in the kitchen\"}',\n",
      "                    'navigation: {\"status\": \"success\", \"message\": \"Moved to '\n",
      "                    'location: kitchen\"}'],\n",
      "           n_executed=2)\n",
      "executing next step: {'agent': 'manipulation', 'command': 'pick up the banana', 'parallel': False}\n",
      "\u001b[36;1m\u001b[1;3m[5:writes]\u001b[0m \u001b[1mFinished step 5 with writes to 2 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mplan\u001b[0m -> [{'agent': 'conversation',\n",
      "  'command': 'inform the user that the banana has been found',\n",
      "  'parallel': False}]\n",
      "- \u001b[33;1m\u001b[1;3mcurrent\u001b[0m -> {'agent': 'manipulation', 'command': 'pick up the banana', 'parallel': False}\n",
      "\u001b[36;1m\u001b[1;3m[5:checkpoint]\u001b[0m \u001b[1mState at the end of step 5:\n",
      "\u001b[0m{'current': {'agent': 'manipulation',\n",
      "             'command': 'pick up the banana',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk')],\n",
      " 'n_executed': 2,\n",
      " 'plan': [{'agent': 'conversation',\n",
      "           'command': 'inform the user that the banana has been found',\n",
      "           'parallel': False}],\n",
      " 'results': ['vision: {\"status\": \"success\", \"message\": \"Detected objects: '\n",
      "             'banana are in the kitchen\"}',\n",
      "             'navigation: {\"status\": \"success\", \"message\": \"Moved to location: '\n",
      "             'kitchen\"}']}\n",
      "\u001b[36;1m\u001b[1;3m[6:tasks]\u001b[0m \u001b[1mStarting 1 task for step 6:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mmanipulation\u001b[0m -> AgentState(messages=[('human', 'Find the banana.'),\n",
      "                     AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk')],\n",
      "           plan=[{'agent': 'conversation',\n",
      "                  'command': 'inform the user that the banana has been found',\n",
      "                  'parallel': False}],\n",
      "           current={'agent': 'manipulation',\n",
      "                    'command': 'pick up the banana',\n",
      "                    'parallel': False},\n",
      "           results=['vision: {\"status\": \"success\", \"message\": \"Detected '\n",
      "                    'objects: banana are in the kitchen\"}',\n",
      "                    'navigation: {\"status\": \"success\", \"message\": \"Moved to '\n",
      "                    'location: kitchen\"}'],\n",
      "           n_executed=2)\n",
      "Picking up object: banana\n",
      "\u001b[36;1m\u001b[1;3m[6:writes]\u001b[0m \u001b[1mFinished step 6 with writes to 4 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('human', 'Find the banana.'),\n",
      " AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7')]\n",
      "- \u001b[33;1m\u001b[1;3mresults\u001b[0m -> ['vision: {\"status\": \"success\", \"message\": \"Detected objects: banana are in '\n",
      " 'the kitchen\"}',\n",
      " 'navigation: {\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}',\n",
      " 'manipulation: {\"status\": \"success\", \"message\": \"Picked up object: banana\"}']\n",
      "- \u001b[33;1m\u001b[1;3mplan\u001b[0m -> [{'agent': 'conversation',\n",
      "  'command': 'inform the user that the banana has been found',\n",
      "  'parallel': False}]\n",
      "- \u001b[33;1m\u001b[1;3mn_executed\u001b[0m -> 3\n",
      "\u001b[36;1m\u001b[1;3m[6:checkpoint]\u001b[0m \u001b[1mState at the end of step 6:\n",
      "\u001b[0m{'current': {'agent': 'manipulation',\n",
      "             'command': 'pick up the banana',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7')],\n",
      " 'n_executed': 3,\n",
      " 'plan': [{'agent': 'conversation',\n",
      "           'command': 'inform the user that the banana has been found',\n",
      "           'parallel': False}],\n",
      " 'results': ['vision: {\"status\": \"success\", \"message\": \"Detected objects: '\n",
      "             'banana are in the kitchen\"}',\n",
      "             'navigation: {\"status\": \"success\", \"message\": \"Moved to location: '\n",
      "             'kitchen\"}',\n",
      "             'manipulation: {\"status\": \"success\", \"message\": \"Picked up '\n",
      "             'object: banana\"}']}\n",
      "\u001b[36;1m\u001b[1;3m[7:tasks]\u001b[0m \u001b[1mStarting 1 task for step 7:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mplanning\u001b[0m -> AgentState(messages=[('human', 'Find the banana.'),\n",
      "                     AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7')],\n",
      "           plan=[{'agent': 'conversation',\n",
      "                  'command': 'inform the user that the banana has been found',\n",
      "                  'parallel': False}],\n",
      "           current={'agent': 'manipulation',\n",
      "                    'command': 'pick up the banana',\n",
      "                    'parallel': False},\n",
      "           results=['vision: {\"status\": \"success\", \"message\": \"Detected '\n",
      "                    'objects: banana are in the kitchen\"}',\n",
      "                    'navigation: {\"status\": \"success\", \"message\": \"Moved to '\n",
      "                    'location: kitchen\"}',\n",
      "                    'manipulation: {\"status\": \"success\", \"message\": \"Picked up '\n",
      "                    'object: banana\"}'],\n",
      "           n_executed=3)\n",
      "executing next step: {'agent': 'conversation', 'command': 'inform the user that the banana has been found', 'parallel': False}\n",
      "\u001b[36;1m\u001b[1;3m[7:writes]\u001b[0m \u001b[1mFinished step 7 with writes to 2 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mplan\u001b[0m -> []\n",
      "- \u001b[33;1m\u001b[1;3mcurrent\u001b[0m -> {'agent': 'conversation',\n",
      " 'command': 'inform the user that the banana has been found',\n",
      " 'parallel': False}\n",
      "\u001b[36;1m\u001b[1;3m[7:checkpoint]\u001b[0m \u001b[1mState at the end of step 7:\n",
      "\u001b[0m{'current': {'agent': 'conversation',\n",
      "             'command': 'inform the user that the banana has been found',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7')],\n",
      " 'n_executed': 3,\n",
      " 'plan': [],\n",
      " 'results': ['vision: {\"status\": \"success\", \"message\": \"Detected objects: '\n",
      "             'banana are in the kitchen\"}',\n",
      "             'navigation: {\"status\": \"success\", \"message\": \"Moved to location: '\n",
      "             'kitchen\"}',\n",
      "             'manipulation: {\"status\": \"success\", \"message\": \"Picked up '\n",
      "             'object: banana\"}']}\n",
      "\u001b[36;1m\u001b[1;3m[8:tasks]\u001b[0m \u001b[1mStarting 1 task for step 8:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mconversation\u001b[0m -> AgentState(messages=[('human', 'Find the banana.'),\n",
      "                     AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7')],\n",
      "           plan=[],\n",
      "           current={'agent': 'conversation',\n",
      "                    'command': 'inform the user that the banana has been found',\n",
      "                    'parallel': False},\n",
      "           results=['vision: {\"status\": \"success\", \"message\": \"Detected '\n",
      "                    'objects: banana are in the kitchen\"}',\n",
      "                    'navigation: {\"status\": \"success\", \"message\": \"Moved to '\n",
      "                    'location: kitchen\"}',\n",
      "                    'manipulation: {\"status\": \"success\", \"message\": \"Picked up '\n",
      "                    'object: banana\"}'],\n",
      "           n_executed=3)\n",
      "Speaking text: The banana has been found.\n",
      "\u001b[36;1m\u001b[1;3m[8:writes]\u001b[0m \u001b[1mFinished step 8 with writes to 4 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('human', 'Find the banana.'),\n",
      " AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'function': {'arguments': '{\"text\":\"The banana has been found.\"}', 'name': 'speak'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 379, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuS7Fbrxc3MTC7E00o9yvnrWx60', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a6d1eade-5e5f-4e2b-8168-99e81f929411-0', tool_calls=[{'name': 'speak', 'args': {'text': 'The banana has been found.'}, 'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 19, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', name='speak', tool_call_id='call_16mNwoMpdwbxndUJvrBMvzjd')]\n",
      "- \u001b[33;1m\u001b[1;3mresults\u001b[0m -> ['vision: {\"status\": \"success\", \"message\": \"Detected objects: banana are in '\n",
      " 'the kitchen\"}',\n",
      " 'navigation: {\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}',\n",
      " 'manipulation: {\"status\": \"success\", \"message\": \"Picked up object: banana\"}',\n",
      " 'conversation: {\"status\": \"success\", \"message\": \"Spoken text: The banana has '\n",
      " 'been found.\"}']\n",
      "- \u001b[33;1m\u001b[1;3mplan\u001b[0m -> []\n",
      "- \u001b[33;1m\u001b[1;3mn_executed\u001b[0m -> 4\n",
      "\u001b[36;1m\u001b[1;3m[8:checkpoint]\u001b[0m \u001b[1mState at the end of step 8:\n",
      "\u001b[0m{'current': {'agent': 'conversation',\n",
      "             'command': 'inform the user that the banana has been found',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'function': {'arguments': '{\"text\":\"The banana has been found.\"}', 'name': 'speak'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 379, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuS7Fbrxc3MTC7E00o9yvnrWx60', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a6d1eade-5e5f-4e2b-8168-99e81f929411-0', tool_calls=[{'name': 'speak', 'args': {'text': 'The banana has been found.'}, 'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 19, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', name='speak', tool_call_id='call_16mNwoMpdwbxndUJvrBMvzjd')],\n",
      " 'n_executed': 4,\n",
      " 'plan': [],\n",
      " 'results': ['vision: {\"status\": \"success\", \"message\": \"Detected objects: '\n",
      "             'banana are in the kitchen\"}',\n",
      "             'navigation: {\"status\": \"success\", \"message\": \"Moved to location: '\n",
      "             'kitchen\"}',\n",
      "             'manipulation: {\"status\": \"success\", \"message\": \"Picked up '\n",
      "             'object: banana\"}',\n",
      "             'conversation: {\"status\": \"success\", \"message\": \"Spoken text: The '\n",
      "             'banana has been found.\"}']}\n",
      "\u001b[36;1m\u001b[1;3m[9:tasks]\u001b[0m \u001b[1mStarting 1 task for step 9:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mplanning\u001b[0m -> AgentState(messages=[('human', 'Find the banana.'),\n",
      "                     AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7'),\n",
      "                     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'function': {'arguments': '{\"text\":\"The banana has been found.\"}', 'name': 'speak'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 379, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuS7Fbrxc3MTC7E00o9yvnrWx60', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a6d1eade-5e5f-4e2b-8168-99e81f929411-0', tool_calls=[{'name': 'speak', 'args': {'text': 'The banana has been found.'}, 'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 19, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                     ToolMessage(content='{\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', name='speak', tool_call_id='call_16mNwoMpdwbxndUJvrBMvzjd')],\n",
      "           plan=[],\n",
      "           current={'agent': 'conversation',\n",
      "                    'command': 'inform the user that the banana has been found',\n",
      "                    'parallel': False},\n",
      "           results=['vision: {\"status\": \"success\", \"message\": \"Detected '\n",
      "                    'objects: banana are in the kitchen\"}',\n",
      "                    'navigation: {\"status\": \"success\", \"message\": \"Moved to '\n",
      "                    'location: kitchen\"}',\n",
      "                    'manipulation: {\"status\": \"success\", \"message\": \"Picked up '\n",
      "                    'object: banana\"}',\n",
      "                    'conversation: {\"status\": \"success\", \"message\": \"Spoken '\n",
      "                    'text: The banana has been found.\"}'],\n",
      "           n_executed=4)\n",
      "No more steps in the plan.\n",
      "\u001b[36;1m\u001b[1;3m[9:writes]\u001b[0m \u001b[1mFinished step 9 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('human', 'Find the banana.'),\n",
      " AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7'),\n",
      " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'function': {'arguments': '{\"text\":\"The banana has been found.\"}', 'name': 'speak'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 379, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuS7Fbrxc3MTC7E00o9yvnrWx60', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a6d1eade-5e5f-4e2b-8168-99e81f929411-0', tool_calls=[{'name': 'speak', 'args': {'text': 'The banana has been found.'}, 'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 19, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='{\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', name='speak', tool_call_id='call_16mNwoMpdwbxndUJvrBMvzjd'),\n",
      " AIMessage(content='Here is what happened:\\nvision: {\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}\\nnavigation: {\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}\\nmanipulation: {\"status\": \"success\", \"message\": \"Picked up object: banana\"}\\nconversation: {\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', additional_kwargs={}, response_metadata={})]\n",
      "\u001b[36;1m\u001b[1;3m[9:checkpoint]\u001b[0m \u001b[1mState at the end of step 9:\n",
      "\u001b[0m{'current': {'agent': 'conversation',\n",
      "             'command': 'inform the user that the banana has been found',\n",
      "             'parallel': False},\n",
      " 'messages': [('human', 'Find the banana.'),\n",
      "              AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'function': {'arguments': '{\"text\":\"The banana has been found.\"}', 'name': 'speak'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 379, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuS7Fbrxc3MTC7E00o9yvnrWx60', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a6d1eade-5e5f-4e2b-8168-99e81f929411-0', tool_calls=[{'name': 'speak', 'args': {'text': 'The banana has been found.'}, 'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 19, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', name='speak', tool_call_id='call_16mNwoMpdwbxndUJvrBMvzjd'),\n",
      "              AIMessage(content='Here is what happened:\\nvision: {\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}\\nnavigation: {\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}\\nmanipulation: {\"status\": \"success\", \"message\": \"Picked up object: banana\"}\\nconversation: {\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', additional_kwargs={}, response_metadata={})],\n",
      " 'n_executed': 4,\n",
      " 'plan': [],\n",
      " 'results': ['vision: {\"status\": \"success\", \"message\": \"Detected objects: '\n",
      "             'banana are in the kitchen\"}',\n",
      "             'navigation: {\"status\": \"success\", \"message\": \"Moved to location: '\n",
      "             'kitchen\"}',\n",
      "             'manipulation: {\"status\": \"success\", \"message\": \"Picked up '\n",
      "             'object: banana\"}',\n",
      "             'conversation: {\"status\": \"success\", \"message\": \"Spoken text: The '\n",
      "             'banana has been found.\"}']}\n",
      "[('human', 'Find the banana.'), AIMessage(content='```python\\n[\\n  {\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false},\\n  {\"agent\": \"navigation\", \"command\": \"navigate to the banana\", \"parallel\": false},\\n  {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false},\\n  {\"agent\": \"conversation\", \"command\": \"inform the user that the banana has been found\", \"parallel\": false}\\n]\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 185, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYBuN9fu3fTW9KYynpDVfV3AACaCQ', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ac38ee5-6b91-45a3-b622-236afd1ced77-0', usage_metadata={'input_tokens': 185, 'output_tokens': 97, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 371, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuP7bR61evTrefL6DibPN8266oE', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9cb63644-0c1e-45e7-ab04-3688be1478bc-0', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_lRAIXgvndRzekKkauVAxDimC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 371, 'output_tokens': 15, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}', name='detect_objects', tool_call_id='call_lRAIXgvndRzekKkauVAxDimC'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'function': {'arguments': '{\"location_name\":\"kitchen\"}', 'name': 'go_to_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 668, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYBuQCvvQxC99prC3EQF8L74fj5H0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec306e7-45c2-4f9f-8a85-4336387677cd-0', tool_calls=[{'name': 'go_to_location', 'args': {'location_name': 'kitchen'}, 'id': 'call_s1AdFXyCovpDHWg0G49MWhUk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 668, 'output_tokens': 17, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}', name='go_to_location', tool_call_id='call_s1AdFXyCovpDHWg0G49MWhUk'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'function': {'arguments': '{\"object_name\":\"banana\"}', 'name': 'pick_up_object'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 524, 'total_tokens': 540, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYBuRqiVtVLiKorgYhHMfAacOwdeK', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9035fcbc-6a25-4d3c-a959-465b52467000-0', tool_calls=[{'name': 'pick_up_object', 'args': {'object_name': 'banana'}, 'id': 'call_GVBRdNqvcJUYHuiQRk1nUCZ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 524, 'output_tokens': 16, 'total_tokens': 540, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"status\": \"success\", \"message\": \"Picked up object: banana\"}', name='pick_up_object', tool_call_id='call_GVBRdNqvcJUYHuiQRk1nUCZ7'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'function': {'arguments': '{\"text\":\"The banana has been found.\"}', 'name': 'speak'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 379, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BYBuS7Fbrxc3MTC7E00o9yvnrWx60', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a6d1eade-5e5f-4e2b-8168-99e81f929411-0', tool_calls=[{'name': 'speak', 'args': {'text': 'The banana has been found.'}, 'id': 'call_16mNwoMpdwbxndUJvrBMvzjd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 19, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', name='speak', tool_call_id='call_16mNwoMpdwbxndUJvrBMvzjd'), AIMessage(content='Here is what happened:\\nvision: {\"status\": \"success\", \"message\": \"Detected objects: banana are in the kitchen\"}\\nnavigation: {\"status\": \"success\", \"message\": \"Moved to location: kitchen\"}\\nmanipulation: {\"status\": \"success\", \"message\": \"Picked up object: banana\"}\\nconversation: {\"status\": \"success\", \"message\": \"Spoken text: The banana has been found.\"}', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# 7.  QUICK MANUAL TEST\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if __name__ == \"__main__\":\n",
    "    user_msg = (\"human\", \"Find the banana.\")\n",
    "    final = graph.invoke({\"messages\": [user_msg]}, debug=True)\n",
    "    print(final[\"messages\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ee7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb157a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "draft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
