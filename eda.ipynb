{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08faf596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb78d039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load env variables from .env file\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122216f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_id = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=0.05,  # <-- Super slow! We can only make a request once every 10 seconds!!\n",
    "    check_every_n_seconds=0.1,  # Wake up every 100 ms to check whether allowed to make a request,\n",
    "    max_bucket_size=10,  # Controls the maximum burst size.\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "# graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28238567",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph must have an entrypoint: add at least one edge from START to another node",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/graph/state.py:539\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[0;34m(self, checkpointer, store, interrupt_before, interrupt_after, debug, name)\u001b[0m\n\u001b[1;32m    536\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[1;32m    548\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m     ]\n\u001b[1;32m    557\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/draft/lib/python3.10/site-packages/langgraph/graph/graph.py:377\u001b[0m, in \u001b[0;36mGraph.validate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound edge starting at unknown node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# assemble targets\u001b[39;00m\n\u001b[1;32m    382\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m {end \u001b[38;5;28;01mfor\u001b[39;00m _, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_edges}\n",
      "\u001b[0;31mValueError\u001b[0m: Graph must have an entrypoint: add at least one edge from START to another node"
     ]
    }
   ],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f688b051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30167934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm **DeepSeek Chat**, an AI assistant created by **DeepSeek**, and hereâ€™s what I can do for you:  \n",
      "\n",
      "### ðŸ” **Knowledge & Assistance**  \n",
      "- Answer questions on diverse topics (science, history, tech, entertainment, etc.).  \n",
      "- Provide explanations, summaries, and detailed analyses.  \n",
      "- Offer step-by-step problem-solving for math, coding, and logic puzzles.  \n",
      "\n",
      "### ðŸ“„ **Document Processing**  \n",
      "- Read and analyze uploaded documents (**PDFs, Word, Excel, PowerPoint, TXT**).  \n",
      "- Extract key information, summarize content, or answer questions about the document.  \n",
      "\n",
      "### ðŸ“ **Writing & Editing**  \n",
      "- Help with essays, reports, emails, and creative writing (stories, poems, scripts).  \n",
      "- Rewrite, proofread, or refine your text for clarity and style.  \n",
      "\n",
      "### ðŸ’» **Coding & Tech Support**  \n",
      "- Write, debug, and optimize code in Python, Java, C++, JavaScript, and more.  \n",
      "- Explain programming concepts, algorithms, and best practices.  \n",
      "\n",
      "### ðŸŒ **Translation & Language Skills**  \n",
      "- Translate between multiple languages (accurate but not perfect).  \n",
      "- Teach vocabulary, grammar, and conversational phrases.  \n",
      "\n",
      "### ðŸ”¢ **Math & Data Analysis**  \n",
      "- Solve equations, explain mathematical theories, and assist with statistics.  \n",
      "- Generate charts, graphs (via explanations), and help with data formatting.  \n",
      "\n",
      "### ðŸŽ­ **Creative & Fun Stuff**  \n",
      "- Generate jokes, stories, movie plots, and roleplay scenarios.  \n",
      "- Assist with brainstorming ideas for projects, branding, or content.  \n",
      "\n",
      "### âš¡ **Limitations** (for transparency)  \n",
      "- My knowledge is **updated until July 2024** (no real-time info).  \n",
      "- I cannot access images/audioâ€”only text from documents.  \n",
      "- I wonâ€™t perform illegal or harmful tasks.  \n",
      "\n",
      "Need something specific? Just askâ€”Iâ€™m happy to help! ðŸš€\n",
      "Assistant: Iâ€™m **DeepSeek Chat**, an AI assistant created by **DeepSeek**. My goal is to help you with information, answer your questions, and assist with tasks like research, writing, coding, and more! ðŸ˜Š  \n",
      "\n",
      "Iâ€™m powered by **DeepSeek-V3**, a large language model with a knowledge cutoff in **July 2024**, and I can even search the web (if you enable it) for the latest updates.  \n",
      "\n",
      "Feel free to ask me anythingâ€”Iâ€™m here to help! ðŸš€\n",
      "User: What do you know about LangGraph?\n",
      "Assistant: **LangGraph** is a library developed by **LangChain** designed for building stateful, multi-actor applications with **Large Language Models (LLMs)**. It extends LangChain's core functionality by enabling the creation of cyclic, stateful workflows (graphs) where multiple agents or nodes can interact dynamically.\n",
      "\n",
      "### **Key Features of LangGraph:**\n",
      "1. **Stateful Workflows**  \n",
      "   - Unlike traditional linear chains, LangGraph allows cycles and state persistence, making it suitable for complex, iterative processes (e.g., multi-agent debates, recursive reasoning).\n",
      "\n",
      "2. **Multi-Agent Collaboration**  \n",
      "   - Supports multiple AI agents (or human actors) working together, passing messages and updating shared state.\n",
      "\n",
      "3. **Flexible Control Flow**  \n",
      "   - Combines **directed graphs** (for structured flows) with **cycles** (for loops, feedback, or self-correction).  \n",
      "   - Example: An agent can refine its answer iteratively based on feedback.\n",
      "\n",
      "4. **Integration with LangChain**  \n",
      "   - Works seamlessly with LangChain's existing tools (models, retrievers, prompts, etc.) while adding advanced orchestration.\n",
      "\n",
      "5. **Human-in-the-Loop**  \n",
      "   - Supports human input at specific points in the workflow (e.g., approval steps).\n",
      "\n",
      "---\n",
      "\n",
      "### **Use Cases**\n",
      "- **Agent Simulations**: Simulate interactions between multiple AI agents.  \n",
      "- **Recursive Problem-Solving**: Tasks requiring refinement (e.g., code generation with error correction).  \n",
      "- **Dynamic Chatbots**: Multi-turn conversations with memory.  \n",
      "- **Decision-Making Pipelines**: Workflows where intermediate steps influence later actions.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example Workflow**\n",
      "A simple LangGraph workflow might involve:\n",
      "1. An **LLM node** generating an answer.  \n",
      "2. A **validator node** checking the answer.  \n",
      "3. A **feedback loop** to refine the answer if validation fails.  \n",
      "\n",
      "```python\n",
      "from langgraph.graph import Graph\n",
      "\n",
      "workflow = Graph()\n",
      "\n",
      "# Define nodes (e.g., LLM calls, tools)\n",
      "workflow.add_node(\"generate\", generate_response)\n",
      "workflow.add_node(\"validate\", validate_response)\n",
      "\n",
      "# Define edges (control flow)\n",
      "workflow.add_edge(\"generate\", \"validate\")\n",
      "workflow.add_conditional_edges(\"validate\", decide_to_finish_or_retry)\n",
      "\n",
      "# Compile and run\n",
      "app = workflow.compile()\n",
      "app.invoke({\"question\": \"...\"})\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Comparison to LangChain**\n",
      "- **LangChain**: Focuses on linear chains (prompt â†’ LLM â†’ output).  \n",
      "- **LangGraph**: Extends this with cycles, state, and multi-agent coordination.  \n",
      "\n",
      "---\n",
      "\n",
      "### **Getting Started**\n",
      "- **Installation**:  \n",
      "  ```bash\n",
      "  pip install langgraph\n",
      "  ```\n",
      "- **Documentation**:  \n",
      "  Check the [LangGraph GitHub](https://github.com/langchain-ai/langgraph) or [LangChain docs](https://python.langchain.com/docs/langgraph).\n",
      "\n",
      "Would you like a deeper dive into a specific feature or use case?\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9752a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from enum import Enum\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class LocationEnum(str, Enum):\n",
    "    kitchen = \"kitchen\"\n",
    "    living_room = \"living_room\"\n",
    "    bedroom = \"bedroom\"\n",
    "\n",
    "@tool\n",
    "def go_to_coordinates(x: float, y: float):\n",
    "    \"\"\"\n",
    "    Move the robot to a specific set of coordinates.\n",
    "    Args:\n",
    "        x (float): The x coordinate.\n",
    "        y (float): The y coordinate.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If x or y is not a number.\n",
    "    Example:\n",
    "        >>> go_to_coordinates(10.5, 20.3)\n",
    "        {'status': 'success', 'message': 'Moved to coordinates (10.5, 20.3)'}\n",
    "    Example:\n",
    "        >>> go_to_coordinates(\"10.5\", 20.3)\n",
    "        ValueError: x and y must be numbers.\n",
    "    Example:\n",
    "        >>> go_to_coordinates(10.5, 20.3)\n",
    "        {'status': 'failure', 'message': 'Failed to move to coordinates (10.5, 20.3)'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving to coordinates ({x}, {y})\")\n",
    "    # Here you would add the code to move the robot to the specified coordinates\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved to coordinates ({x}, {y})\"}\n",
    "\n",
    "@tool\n",
    "def go_to_location(location_name: LocationEnum):\n",
    "    \"\"\"\n",
    "    Move the robot to a specific location.\n",
    "    Args:\n",
    "        location_name (LocationEnum): The name of the location.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If location_name is not a valid location.\n",
    "    Example:\n",
    "        >>> go_to_location(\"kitchen\")\n",
    "        {'status': 'success', 'message': 'Moved to location: kitchen'}\n",
    "    Example:\n",
    "        >>> go_to_location(\"garage\")\n",
    "        ValueError: location_name must be one of ['kitchen', 'living_room', 'bedroom'].\n",
    "    Example:\n",
    "        >>> go_to_location(\"living_room\")\n",
    "        {'status': 'failure', 'message': 'Failed to move to location: living_room'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving to location: {location_name}\")\n",
    "    # Here you would add the code to move the robot to the specified location\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved to location: {location_name}\"}\n",
    "\n",
    "@tool\n",
    "def rotate(angle: float):\n",
    "    \"\"\"\n",
    "    Rotate the robot to a specific angle.\n",
    "    Args:\n",
    "        angle (float): The angle to rotate to.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Raises:\n",
    "        ValueError: If angle is not a number.\n",
    "    Example:\n",
    "        >>> rotate(90)\n",
    "        {'status': 'success', 'message': 'Rotated to angle: 90'}\n",
    "    Example:\n",
    "        >>> rotate(\"90\")\n",
    "        ValueError: angle must be a number.\n",
    "    Example:\n",
    "        >>> rotate(90)\n",
    "        {'status': 'failure', 'message': 'Failed to rotate to angle: 90'}\n",
    "    \"\"\"\n",
    "    print(f\"Rotating to angle: {angle}\")\n",
    "    # Here you would add the code to rotate the robot to the specified angle\n",
    "    return {\"status\": \"success\", \"message\": f\"Rotated to angle: {angle}\"}\n",
    "\n",
    "@tool\n",
    "def get_pose():\n",
    "    \"\"\"\n",
    "    Get the current pose of the robot.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> get_pose()\n",
    "        {'status': 'success', 'message': 'Current pose: (x, y, theta)'}\n",
    "    Example:\n",
    "        >>> get_pose()\n",
    "        {'status': 'failure', 'message': 'Failed to get pose'}\n",
    "    \"\"\"\n",
    "    print(\"Getting current pose\")\n",
    "    # Here you would add the code to get the current pose of the robot\n",
    "    return {\"status\": \"success\", \"message\": \"Current pose: (x, y, theta)\"}\n",
    "\n",
    "@tool\n",
    "def follow_person():\n",
    "    \"\"\"\n",
    "    Follow a person.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> follow_person()\n",
    "        {'status': 'success', 'message': 'Following person'}\n",
    "    Example:\n",
    "        >>> follow_person()\n",
    "        {'status': 'failure', 'message': 'Failed to follow person'}\n",
    "    \"\"\"\n",
    "    print(\"Following person\")\n",
    "    # Here you would add the code to follow a person\n",
    "    return {\"status\": \"success\", \"message\": \"Following person\"}\n",
    "\n",
    "nav_tools = [\n",
    "    go_to_coordinates,\n",
    "    go_to_location,\n",
    "    rotate,\n",
    "    get_pose,\n",
    "    follow_person\n",
    "]\n",
    "nav_llm_with_tools = llm.bind_tools(nav_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3221a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent system prompts\n",
    "sub_str = \"\"\"\n",
    "                'plan': \\[\n",
    "                            \\{'tool': 'tool_name': parameters: \\[param1,...,paramN\\], 'parallel': True/False \\},\n",
    "                            ...\n",
    "                        \\]\n",
    "        \"\"\"\n",
    "agent_sys_msg = lambda module: f\"\"\"You are the {module} head of a Robot, you have access to a set of tools that represent the robot's capabilities and\n",
    "                        you are tasked with translating a user's natural language command to one of the available tools with the appropriate parameters.\n",
    "                        Note that you can chain several tools together to fulfill a user command, you can also specify whether to run tools in parallel or sequentially.\n",
    "                        You have a set of tools at your disposal, each with its own set of parameters, you can call the tools, but you must\n",
    "                        also provide a concise reasoning for your choice in the tool_messages section for each one of the tool_calls.\n",
    "                        \"\"\"\n",
    "\n",
    "planning_sys_msg = \"\"\"You are the planning head of a robot that has several capabilities, you have access to several specialized agents,\n",
    "                        each with its own set of capabilities.\n",
    "                        You are tasked with finding the best plan to execute on the user's command based on the agents you have at disposal\n",
    "                        and their capabilities.\n",
    "                        You can also specify wheter to run commands sequentially or in parallel.\n",
    "                        Your output should be very precise and concise.\n",
    "                        The agent names are the following: [\"conversation\", \"manipulation\", \"navigation\", \"vision\"]\n",
    "                        Output format:\n",
    "                        'reasoning': Explain the overarching goal and how you plan to achieve it (be very concise)\n",
    "                        'plan': \\[\n",
    "                                    \\{'agent': 'agent_name', 'command': 'the command to be run by the agent', 'parallel': True/False \\},\n",
    "                                    ...\n",
    "                                \\]\n",
    "                        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ce3f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "def navigation_agent(state: MessagesState):\n",
    "    return {\"messages\": [nav_llm_with_tools.invoke([agent_sys_msg(module=\"navigation\")] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4bffb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation tools\n",
    "\n",
    "@tool\n",
    "def move_arm(x: float, y: float):\n",
    "    \"\"\"\n",
    "    Move the robot's arm to a specific position.\n",
    "    Args:\n",
    "        x (float): The x coordinate.\n",
    "        y (float): The y coordinate.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> move_arm(10.5, 20.3)\n",
    "        {'status': 'success', 'message': 'Moved arm to coordinates (10.5, 20.3)'}\n",
    "    Example:\n",
    "        >>> move_arm(\"10.5\", 20.3)\n",
    "        ValueError: x and y must be numbers.\n",
    "    Example:\n",
    "        >>> move_arm(10.5, 20.3)\n",
    "        {'status': 'failure', 'message': 'Failed to move arm to coordinates (10.5, 20.3)'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving arm to coordinates ({x}, {y})\")\n",
    "    # Here you would add the code to move the robot's arm to the specified coordinates\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved arm to coordinates ({x}, {y})\"}\n",
    "\n",
    "@tool\n",
    "def move_joints(joint_angles: list):\n",
    "    \"\"\"\n",
    "    Move the robot's joints to specific angles.\n",
    "    Args:\n",
    "        joint_angles (list): A list of joint angles.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> move_joints([30, 45, 60])\n",
    "        {'status': 'success', 'message': 'Moved joints to angles [30, 45, 60]'}\n",
    "    Example:\n",
    "        >>> move_joints(\"30, 45, 60\")\n",
    "        ValueError: joint_angles must be a list of numbers.\n",
    "    Example:\n",
    "        >>> move_joints([30, 45, 60])\n",
    "        {'status': 'failure', 'message': 'Failed to move joints to angles [30, 45, 60]'}\n",
    "    \"\"\"\n",
    "    print(f\"Moving joints to angles {joint_angles}\")\n",
    "    # Here you would add the code to move the robot's joints to the specified angles\n",
    "    return {\"status\": \"success\", \"message\": f\"Moved joints to angles {joint_angles}\"}\n",
    "\n",
    "@tool\n",
    "def pick_up_object(object_name: str):\n",
    "    \"\"\"\n",
    "    Pick up an object.\n",
    "    Args:\n",
    "        object_name (str): The name of the object to pick up.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> pick_up_object(\"box\")\n",
    "        {'status': 'success', 'message': 'Picked up object: box'}\n",
    "    Example:\n",
    "        >>> pick_up_object(123)\n",
    "        ValueError: object_name must be a string.\n",
    "    Example:\n",
    "        >>> pick_up_object(\"box\")\n",
    "        {'status': 'failure', 'message': 'Failed to pick up object: box'}\n",
    "    \"\"\"\n",
    "    print(f\"Picking up object: {object_name}\")\n",
    "    # Here you would add the code to pick up the specified object\n",
    "    return {\"status\": \"success\", \"message\": f\"Picked up object: {object_name}\"}\n",
    "\n",
    "@tool\n",
    "def press_button(button_name: str):\n",
    "    \"\"\"\n",
    "    Press a button.\n",
    "    Args:\n",
    "        button_name (str): The name of the button to press.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> press_button(\"start\")\n",
    "        {'status': 'success', 'message': 'Pressed button: start'}\n",
    "    Example:\n",
    "        >>> press_button(123)\n",
    "        ValueError: button_name must be a string.\n",
    "    Example:\n",
    "        >>> press_button(\"start\")\n",
    "        {'status': 'failure', 'message': 'Failed to press button: start'}\n",
    "    \"\"\"\n",
    "    print(f\"Pressing button: {button_name}\")\n",
    "    # Here you would add the code to press the specified button\n",
    "    return {\"status\": \"success\", \"message\": f\"Pressed button: {button_name}\"}\n",
    "\n",
    "manip_llm = ChatOpenAI(\n",
    "        \n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "manip_tools = [\n",
    "    move_arm,\n",
    "    move_joints,\n",
    "    pick_up_object\n",
    "]\n",
    "manip_llm_with_tools = manip_llm.bind_tools(manip_tools)\n",
    "def manipulation_agent(state: MessagesState):\n",
    "    return {\"messages\": [manip_llm_with_tools.invoke([agent_sys_msg(module=\"navigation\")] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e735f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e45be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision tools\n",
    "\n",
    "@tool\n",
    "def take_picture():\n",
    "    \"\"\"\n",
    "    Take a picture.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> take_picture()\n",
    "        {'status': 'success', 'message': 'Picture taken'}\n",
    "    Example:\n",
    "        >>> take_picture()\n",
    "        {'status': 'failure', 'message': 'Failed to take picture'}\n",
    "    \"\"\"\n",
    "    print(\"Taking picture\")\n",
    "    # Here you would add the code to take a picture\n",
    "    return {\"status\": \"success\", \"message\": \"Picture taken\"}\n",
    "\n",
    "@tool\n",
    "def detect_objects(objects: List[str]):\n",
    "    \"\"\"\n",
    "    Detect objects in the environment.\n",
    "    Args:\n",
    "        objects (List[str]): A list of object names to detect.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> detect_objects([\"box\", \"chair\"])\n",
    "        {'status': 'success', 'message': 'Detected objects: box, chair'}\n",
    "    Example:\n",
    "        >>> detect_objects(\"box, chair\")\n",
    "        ValueError: objects must be a list of strings.\n",
    "    Example:\n",
    "        >>> detect_objects([\"box\", \"chair\"])\n",
    "        {'status': 'failure', 'message': 'Failed to detect objects: box, chair'}\n",
    "    \"\"\"\n",
    "    print(f\"Detecting objects: {objects}\")\n",
    "    # Here you would add the code to detect the specified objects\n",
    "    return {\"status\": \"success\", \"message\": f\"Detected objects: {', '.join(objects)}\"}\n",
    "\n",
    "@tool\n",
    "def recognize_text():\n",
    "    \"\"\"\n",
    "    Recognize text in the environment.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> recognize_text()\n",
    "        {'status': 'success', 'message': 'Recognized text: Hello, world!'}\n",
    "    Example:\n",
    "        >>> recognize_text()\n",
    "        {'status': 'failure', 'message': 'Failed to recognize text'}\n",
    "    \"\"\"\n",
    "    print(\"Recognizing text\")\n",
    "    # Here you would add the code to recognize text\n",
    "    return {\"status\": \"success\", \"message\": \"Recognized text: Hello, world!\"}\n",
    "\n",
    "@tool\n",
    "def semantic_segmentation():\n",
    "    \"\"\"\n",
    "    Perform semantic segmentation.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> semantic_segmentation()\n",
    "        {'status': 'success', 'message': 'Semantic segmentation completed'}\n",
    "    Example:\n",
    "        >>> semantic_segmentation()\n",
    "        {'status': 'failure', 'message': 'Failed to perform semantic segmentation'}\n",
    "    \"\"\"\n",
    "    print(\"Performing semantic segmentation\")\n",
    "    # Here you would add the code to perform semantic segmentation\n",
    "    return {\"status\": \"success\", \"message\": \"Semantic segmentation completed\"}\n",
    "\n",
    "vision_llm = ChatOpenAI(\n",
    "        \n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "vision_tools = [\n",
    "    take_picture,\n",
    "    detect_objects,\n",
    "    recognize_text,\n",
    "    semantic_segmentation\n",
    "]\n",
    "\n",
    "vision_llm_with_tools = vision_llm.bind_tools(vision_tools)\n",
    "def vision_agent(state: MessagesState):\n",
    "    return {\"messages\": [vision_llm_with_tools.invoke([agent_sys_msg(module=\"vision\")] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41214629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversational tools\n",
    "@tool\n",
    "def clarify(context: str, question: str):\n",
    "    \"\"\"\n",
    "    Clarify a question based on the context.\n",
    "    Args:\n",
    "        context (str): The context to clarify the question.\n",
    "        question (str): The question to clarify.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", \"Where is the robot?\")\n",
    "        {'status': 'success', 'message': 'The robot is in the kitchen.'}\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", 123)\n",
    "        ValueError: question must be a string.\n",
    "    Example:\n",
    "        >>> clarify(\"The robot is in the kitchen.\", \"Where is the robot?\")\n",
    "        {'status': 'failure', 'message': 'Failed to clarify the question.'}\n",
    "    \"\"\"\n",
    "    print(f\"Clarifying question: {question} based on context: {context}\")\n",
    "    # Here you would add the code to clarify the question based on the context\n",
    "    return {\"status\": \"success\", \"message\": f\"The robot is in the kitchen.\"}\n",
    "\n",
    "@tool\n",
    "def speak(text: str):\n",
    "    \"\"\"\n",
    "    Speak a given text.\n",
    "    Args:\n",
    "        text (str): The text to speak.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the status and message.\n",
    "    Example:\n",
    "        >>> speak(\"Hello, world!\")\n",
    "        {'status': 'success', 'message': 'Spoken text: Hello, world!'}\n",
    "    Example:\n",
    "        >>> speak(123)\n",
    "        ValueError: text must be a string.\n",
    "    Example:\n",
    "        >>> speak(\"Hello, world!\")\n",
    "        {'status': 'failure', 'message': 'Failed to speak text: Hello, world!'}\n",
    "    \"\"\"\n",
    "    print(f\"Speaking text: {text}\")\n",
    "    # Here you would add the code to speak the given text\n",
    "    return {\"status\": \"success\", \"message\": f\"Spoken text: {text}\"}\n",
    "\n",
    "conv_llm = ChatOpenAI(\n",
    "        \n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "conv_tools = [\n",
    "    clarify,\n",
    "    speak\n",
    "]\n",
    "conv_llm_with_tools = conv_llm.bind_tools(conv_tools)\n",
    "def conv_agent(state: MessagesState):\n",
    "    return {\"messages\": [conv_llm_with_tools.invoke([agent_sys_msg(module=\"conversation\")] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e977c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_llm = ChatOpenAI(\n",
    "        \n",
    "        model=model_id,\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=1000\n",
    "    )\n",
    "\n",
    "def planning_agent(state: MessagesState):\n",
    "    return {\"messages\": [planning_llm.invoke([planning_sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3220d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes to the graph\n",
    "builder.add_node(\"planning\", planning_agent)\n",
    "builder.add_node(\"conversation\", conv_agent)\n",
    "builder.add_node(\"manipulation\", manipulation_agent)\n",
    "builder.add_node(\"navigation\", navigation_agent)\n",
    "builder.add_node(\"vision\", vision_agent)\n",
    "\n",
    "# Define the edges of the graph\n",
    "builder.add_edge(START, \"planning\")\n",
    "\n",
    "# Define a condition function to route messages based on the planning agent's decision\n",
    "def route_to_agent(state):\n",
    "    # Get the last message from the assistant (which should be from the planning agent)\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if \"plan\" not in last_message.content:\n",
    "        return END\n",
    "    \n",
    "    # Try to extract the plan from the message content\n",
    "    # Use regex to extract JSON structure\n",
    "    pattern = r'\\[.*?\\]'\n",
    "    match = re.search(pattern, last_message.content, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            plan_data = literal_eval(match.group().replace(\"\\\\{\", \"{\").replace(\"\\\\}\", \"}\").replace(\"\\[\", \"[\").replace(\"\\]\", \"]\").replace(\"\\\\'\", \"'\"))\n",
    "            if len(plan_data) > 0:\n",
    "                # Get the first agent in the plan\n",
    "                next_step = plan_data[0]\n",
    "                next_agent = next_step[\"agent\"]\n",
    "                \n",
    "                # Update the original state with the modified plan (for future steps)\n",
    "                if plan_data:\n",
    "                    last_message.content = json.dumps(plan_data)\n",
    "                \n",
    "                # Return the next agent to call along with the new state\n",
    "                if next_agent in [\"conversation\", \"manipulation\", \"navigation\", \"vision\"]:\n",
    "                    return next_agent\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "    print(\"No valid plan found or unable to parse the plan.\")\n",
    "    \n",
    "    return END\n",
    "\n",
    "# Add conditional edges from planning to other agents\n",
    "builder.add_conditional_edges(\n",
    "    \"planning\",\n",
    "    route_to_agent,\n",
    "    {\n",
    "        \"conversation\": \"conversation\",\n",
    "        \"manipulation\": \"manipulation\",\n",
    "        \"navigation\": \"navigation\",\n",
    "        \"vision\": \"vision\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edges from other agents back to planning or to END\n",
    "# builder.add_edge(\"conversation\", \"planning\")\n",
    "# builder.add_edge(\"manipulation\", \"planning\")\n",
    "# builder.add_edge(\"navigation\", \"planning\")\n",
    "# builder.add_edge(\"vision\", \"planning\")\n",
    "\n",
    "builder.add_edge([\"conversation\", \"manipulation\", \"navigation\", \"vision\"], END)\n",
    "\n",
    "# Compile the graph\n",
    "react_graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b299b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={})]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={})]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mplanning\u001b[0m -> {'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='[{\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false}, {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-e2dfb813-d2c0-4a59-9be1-dec2848302e0')]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116'),\n",
      "              AIMessage(content='[{\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false}, {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-e2dfb813-d2c0-4a59-9be1-dec2848302e0')]}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 1 task for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mvision\u001b[0m -> {'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116'),\n",
      "              AIMessage(content='[{\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false}, {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-e2dfb813-d2c0-4a59-9be1-dec2848302e0')]}\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_c2wFhAirsr5RNO7ylNDPmBGf', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b'}, id='run-db73a109-348b-4a7b-a97e-f63c4c6eefcc', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_c2wFhAirsr5RNO7ylNDPmBGf', 'type': 'tool_call'}])]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Can you pick up the banana?', additional_kwargs={}, response_metadata={}, id='0d152d9d-8207-489a-bf56-52df34d49116'),\n",
      "              AIMessage(content='[{\"agent\": \"vision\", \"command\": \"locate the banana\", \"parallel\": false}, {\"agent\": \"manipulation\", \"command\": \"pick up the banana\", \"parallel\": false}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-e2dfb813-d2c0-4a59-9be1-dec2848302e0'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_c2wFhAirsr5RNO7ylNDPmBGf', 'function': {'arguments': '{\"objects\":[\"banana\"]}', 'name': 'detect_objects'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b'}, id='run-db73a109-348b-4a7b-a97e-f63c4c6eefcc', tool_calls=[{'name': 'detect_objects', 'args': {'objects': ['banana']}, 'id': 'call_c2wFhAirsr5RNO7ylNDPmBGf', 'type': 'tool_call'}])]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Can you pick up the banana?\")]\n",
    "\n",
    "for chunk in react_graph.stream({\"messages\": messages}, stream_mode=\"messages\", debug=True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76118a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "draft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
